{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m venv myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !myenv\\Scripts\\activate.ps1\n",
    "\n",
    "# !env_ml\\Scripts\\activate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# # Loading the dataset from Hugging Face\n",
    "dataset = load_dataset(\"SetFit/enron_spam\")\n",
    "\n",
    "# # Convert the training set to a Pandas DataFrame\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "test=pd.DataFrame(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33214</td>\n",
       "      <td>any software just for 15 $ - 99 $ understandin...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>any software just for 15 $ - 99 $</td>\n",
       "      <td>understanding oem software\\nlead me not into t...</td>\n",
       "      <td>2005-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11929</td>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>19 th , 2 : 00 pm edt\\nperspective on ferc reg...</td>\n",
       "      <td>2001-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19784</td>\n",
       "      <td>wanted to try ci 4 lis but thought it was way ...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>wanted to try ci 4 lis but thought it was way ...</td>\n",
       "      <td>viagra at $ 1 . 12 per dose\\nready to boost yo...</td>\n",
       "      <td>2004-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2209</td>\n",
       "      <td>enron / hpl actuals for december 11 , 2000 tec...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>enron / hpl actuals for december 11 , 2000</td>\n",
       "      <td>teco tap 30 . 000 / enron ; 120 . 000 / hpl ga...</td>\n",
       "      <td>2000-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15880</td>\n",
       "      <td>looking for cheap high - quality software ? ro...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>looking for cheap high - quality software ? ro...</td>\n",
       "      <td>water past also , burn , course . gave country...</td>\n",
       "      <td>2005-02-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   message_id                                               text  label  \\\n",
       "0       33214  any software just for 15 $ - 99 $ understandin...      1   \n",
       "1       11929  perspective on ferc regulatory action client c...      0   \n",
       "2       19784  wanted to try ci 4 lis but thought it was way ...      1   \n",
       "3        2209  enron / hpl actuals for december 11 , 2000 tec...      0   \n",
       "4       15880  looking for cheap high - quality software ? ro...      1   \n",
       "\n",
       "  label_text                                            subject  \\\n",
       "0       spam                  any software just for 15 $ - 99 $   \n",
       "1        ham  perspective on ferc regulatory action client c...   \n",
       "2       spam  wanted to try ci 4 lis but thought it was way ...   \n",
       "3        ham         enron / hpl actuals for december 11 , 2000   \n",
       "4       spam  looking for cheap high - quality software ? ro...   \n",
       "\n",
       "                                             message       date  \n",
       "0  understanding oem software\\nlead me not into t... 2005-06-18  \n",
       "1  19 th , 2 : 00 pm edt\\nperspective on ferc reg... 2001-06-19  \n",
       "2  viagra at $ 1 . 12 per dose\\nready to boost yo... 2004-09-11  \n",
       "3  teco tap 30 . 000 / enron ; 120 . 000 / hpl ga... 2000-12-12  \n",
       "4  water past also , burn , course . gave country... 2005-02-13  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=df\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31329</td>\n",
       "      <td>expande tu imagen ! ! ! ! ! ! ! ! ! si no pued...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>expande tu imagen ! ! ! ! ! ! ! ! !</td>\n",
       "      <td>si no puede ver este mail , entre a : http : /...</td>\n",
       "      <td>2005-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3969</td>\n",
       "      <td>paliourg learning for life enlarge your member...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>paliourg learning for life</td>\n",
       "      <td>enlarge your member\\nzenextend enlargement pil...</td>\n",
       "      <td>2004-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27070</td>\n",
       "      <td>cure premature ejaculation hello ,\\ndid you ej...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>cure premature ejaculation</td>\n",
       "      <td>hello ,\\ndid you ejaculate before or within a ...</td>\n",
       "      <td>2005-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2779</td>\n",
       "      <td>re : noms / actual flow for 3 / 19 / 01 we agr...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>re : noms / actual flow for 3 / 19 / 01</td>\n",
       "      <td>we agree\\n\" eileen ponton \" on 03 / 20 / 2001 ...</td>\n",
       "      <td>2001-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2949</td>\n",
       "      <td>ehronline web address change this message is i...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>ehronline web address change</td>\n",
       "      <td>this message is intended for ehronline users o...</td>\n",
       "      <td>2001-03-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   message_id                                               text  label  \\\n",
       "0       31329  expande tu imagen ! ! ! ! ! ! ! ! ! si no pued...      1   \n",
       "1        3969  paliourg learning for life enlarge your member...      1   \n",
       "2       27070  cure premature ejaculation hello ,\\ndid you ej...      1   \n",
       "3        2779  re : noms / actual flow for 3 / 19 / 01 we agr...      0   \n",
       "4        2949  ehronline web address change this message is i...      0   \n",
       "\n",
       "  label_text                                  subject  \\\n",
       "0       spam      expande tu imagen ! ! ! ! ! ! ! ! !   \n",
       "1       spam               paliourg learning for life   \n",
       "2       spam               cure premature ejaculation   \n",
       "3        ham  re : noms / actual flow for 3 / 19 / 01   \n",
       "4        ham             ehronline web address change   \n",
       "\n",
       "                                             message       date  \n",
       "0  si no puede ver este mail , entre a : http : /... 2005-01-19  \n",
       "1  enlarge your member\\nzenextend enlargement pil... 2004-05-06  \n",
       "2  hello ,\\ndid you ejaculate before or within a ... 2005-07-17  \n",
       "3  we agree\\n\" eileen ponton \" on 03 / 20 / 2001 ... 2001-03-20  \n",
       "4  this message is intended for ehronline users o... 2001-03-30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=test\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33716, 7)\n",
      "33716\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train_data, test_data], ignore_index=True)\n",
    "print(df.shape)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [message_id, text, label, label_text, subject, message, date]\n",
      "Index: []\n",
      "Cleaned DataFrame shape: (33665, 7)\n"
     ]
    }
   ],
   "source": [
    "# # df\n",
    "# Drop rows where 'text_joined' is empty\n",
    "df = df[df['text'].str.len() > 0]\n",
    "\n",
    "print(df[df['text'].str.len() == 0])  # Find any empty texts\n",
    "\n",
    "\n",
    "# Optionally, reset the index if needed\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the shape of the cleaned DataFrame to verify\n",
    "print(f'Cleaned DataFrame shape: {df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message_id    0\n",
      "text          0\n",
      "label         0\n",
      "label_text    0\n",
      "subject       0\n",
      "message       0\n",
      "date          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    17120\n",
      "0    16545\n",
      "Name: count, dtype: int64\n",
      "Percentage of ham (0): 49.15%\n",
      "Percentage of spam (1): 50.85%\n"
     ]
    }
   ],
   "source": [
    "counts = df['label'].value_counts()\n",
    "print(counts)\n",
    "\n",
    "# Calculate percentages\n",
    "percentages = (counts / len(df)) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Percentage of ham (0): {percentages.get(0, 0):.2f}%\")\n",
    "print(f\"Percentage of spam (1): {percentages.get(1, 0):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for 15 $ - 99 $ understandin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci 4 lis but thought it was way ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron / hpl actuals for december 11 , 2000 tec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high - quality software ? ro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  any software just for 15 $ - 99 $ understandin...      1\n",
       "1  perspective on ferc regulatory action client c...      0\n",
       "2  wanted to try ci 4 lis but thought it was way ...      1\n",
       "3  enron / hpl actuals for december 11 , 2000 tec...      0\n",
       "4  looking for cheap high - quality software ? ro...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Preprocessing\n",
    "# ## Droping columns for train and test dataset.\n",
    "# train_data= train_data.drop(columns=['message_id', 'label_text', 'date', 'subject','message'])\n",
    "df =df.drop(columns=['message_id', 'label_text', 'date', 'message', 'subject'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for 15 $ - 99 $ understandin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci 4 lis but thought it was way ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron / hpl actuals for december 11 , 2000 tec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high - quality software ? ro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  any software just for 15 $ - 99 $ understandin...      1\n",
       "1  perspective on ferc regulatory action client c...      0\n",
       "2  wanted to try ci 4 lis but thought it was way ...      1\n",
       "3  enron / hpl actuals for december 11 , 2000 tec...      0\n",
       "4  looking for cheap high - quality software ? ro...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Text Normalization\n",
    "# ## Lowercasing\n",
    "# # List of columns to apply lowercasing\n",
    "columns_to_lower = ['text']  # Replace with your actual column names\n",
    "\n",
    "# # Apply str.lower() to each column in the list\n",
    "# # train_data[columns_to_lower] = train_data[columns_to_lower].apply(lambda x: x.str.lower())\n",
    "df[columns_to_lower] = df[columns_to_lower].apply(lambda x: x.str.lower())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33665, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Removing punctutaitons \n",
    "import string\n",
    "df['text'] = df['text'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33660</th>\n",
       "      <td>re  book notes vince  look forward to meeting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33661</th>\n",
       "      <td>rollout schedule for unify real  time deal  pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33662</th>\n",
       "      <td>anshuman shrivastava sandeep  vince has asked ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33663</th>\n",
       "      <td>re  good morning john \\ni shall see christie t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33664</th>\n",
       "      <td>customer meeting ngts  whose main headquarters...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      any software just for      understanding oem s...      1\n",
       "1      perspective on ferc regulatory action client c...      0\n",
       "2      wanted to try ci  lis but thought it was way t...      1\n",
       "3      enron  hpl actuals for december    teco tap   ...      0\n",
       "4      looking for cheap high  quality software  rota...      1\n",
       "...                                                  ...    ...\n",
       "33660  re  book notes vince  look forward to meeting ...      0\n",
       "33661  rollout schedule for unify real  time deal  pa...      0\n",
       "33662  anshuman shrivastava sandeep  vince has asked ...      0\n",
       "33663  re  good morning john \\ni shall see christie t...      0\n",
       "33664  customer meeting ngts  whose main headquarters...      0\n",
       "\n",
       "[33665 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Removing numbers and special charectors\n",
    "df['text'] = df['text'].str.replace(r'\\d+', '', regex=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33660</th>\n",
       "      <td>re  book notes vince  look forward to meeting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33661</th>\n",
       "      <td>rollout schedule for unify real  time deal  pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33662</th>\n",
       "      <td>anshuman shrivastava sandeep  vince has asked ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33663</th>\n",
       "      <td>re  good morning john \\ni shall see christie t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33664</th>\n",
       "      <td>customer meeting ngts  whose main headquarters...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      any software just for      understanding oem s...      1\n",
       "1      perspective on ferc regulatory action client c...      0\n",
       "2      wanted to try ci  lis but thought it was way t...      1\n",
       "3      enron  hpl actuals for december    teco tap   ...      0\n",
       "4      looking for cheap high  quality software  rota...      1\n",
       "...                                                  ...    ...\n",
       "33660  re  book notes vince  look forward to meeting ...      0\n",
       "33661  rollout schedule for unify real  time deal  pa...      0\n",
       "33662  anshuman shrivastava sandeep  vince has asked ...      0\n",
       "33663  re  good morning john \\ni shall see christie t...      0\n",
       "33664  customer meeting ngts  whose main headquarters...      0\n",
       "\n",
       "[33665 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Removing WHite spaces\n",
    "df['text'] = df['text'].str.strip()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk \n",
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[any, software, just, for, understanding, oem,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[perspective, on, ferc, regulatory, action, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wanted, to, try, ci, lis, but, thought, it, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[enron, hpl, actuals, for, december, teco, tap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "      <td>[looking, for, cheap, high, quality, software,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  any software just for      understanding oem s...      1   \n",
       "1  perspective on ferc regulatory action client c...      0   \n",
       "2  wanted to try ci  lis but thought it was way t...      1   \n",
       "3  enron  hpl actuals for december    teco tap   ...      0   \n",
       "4  looking for cheap high  quality software  rota...      1   \n",
       "\n",
       "                                         text_tokens  \n",
       "0  [any, software, just, for, understanding, oem,...  \n",
       "1  [perspective, on, ferc, regulatory, action, cl...  \n",
       "2  [wanted, to, try, ci, lis, but, thought, it, w...  \n",
       "3  [enron, hpl, actuals, for, december, teco, tap...  \n",
       "4  [looking, for, cheap, high, quality, software,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenization \n",
    "from nltk.tokenize import word_tokenize\n",
    "df['text_tokens'] = df['text'].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33665, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[software, understanding, oem, software, lead,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[perspective, ferc, regulatory, action, client...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wanted, try, ci, lis, thought, way, expensive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[enron, hpl, actuals, december, teco, tap, enr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "      <td>[looking, cheap, high, quality, software, rota...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  any software just for      understanding oem s...      1   \n",
       "1  perspective on ferc regulatory action client c...      0   \n",
       "2  wanted to try ci  lis but thought it was way t...      1   \n",
       "3  enron  hpl actuals for december    teco tap   ...      0   \n",
       "4  looking for cheap high  quality software  rota...      1   \n",
       "\n",
       "                                         text_tokens  \n",
       "0  [software, understanding, oem, software, lead,...  \n",
       "1  [perspective, ferc, regulatory, action, client...  \n",
       "2  [wanted, try, ci, lis, thought, way, expensive...  \n",
       "3  [enron, hpl, actuals, december, teco, tap, enr...  \n",
       "4  [looking, cheap, high, quality, software, rota...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STOPWORDS REMOVAL \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['text_tokens'] = df['text_tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33665, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[software, understanding, oem, software, lead,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[perspective, ferc, regulatory, action, client...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wanted, try, ci, li, thought, way, expensive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[enron, hpl, actuals, december, teco, tap, enr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "      <td>[looking, cheap, high, quality, software, rota...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  any software just for      understanding oem s...      1   \n",
       "1  perspective on ferc regulatory action client c...      0   \n",
       "2  wanted to try ci  lis but thought it was way t...      1   \n",
       "3  enron  hpl actuals for december    teco tap   ...      0   \n",
       "4  looking for cheap high  quality software  rota...      1   \n",
       "\n",
       "                                         text_tokens  \n",
       "0  [software, understanding, oem, software, lead,...  \n",
       "1  [perspective, ferc, regulatory, action, client...  \n",
       "2  [wanted, try, ci, li, thought, way, expensive,...  \n",
       "3  [enron, hpl, actuals, december, teco, tap, enr...  \n",
       "4  [looking, cheap, high, quality, software, rota...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lemmatization \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['text_tokens'] = df['text_tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33665, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[software, understanding, oem, software, lead,...</td>\n",
       "      <td>software understanding oem software lead tempt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[perspective, ferc, regulatory, action, client...</td>\n",
       "      <td>perspective ferc regulatory action client conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wanted, try, ci, li, thought, way, expensive,...</td>\n",
       "      <td>wanted try ci li thought way expensive viagra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[enron, hpl, actuals, december, teco, tap, enr...</td>\n",
       "      <td>enron hpl actuals december teco tap enron hpl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "      <td>[looking, cheap, high, quality, software, rota...</td>\n",
       "      <td>looking cheap high quality software rotated na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  any software just for      understanding oem s...      1   \n",
       "1  perspective on ferc regulatory action client c...      0   \n",
       "2  wanted to try ci  lis but thought it was way t...      1   \n",
       "3  enron  hpl actuals for december    teco tap   ...      0   \n",
       "4  looking for cheap high  quality software  rota...      1   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [software, understanding, oem, software, lead,...   \n",
       "1  [perspective, ferc, regulatory, action, client...   \n",
       "2  [wanted, try, ci, li, thought, way, expensive,...   \n",
       "3  [enron, hpl, actuals, december, teco, tap, enr...   \n",
       "4  [looking, cheap, high, quality, software, rota...   \n",
       "\n",
       "                                         text_joined  \n",
       "0  software understanding oem software lead tempt...  \n",
       "1  perspective ferc regulatory action client conf...  \n",
       "2  wanted try ci li thought way expensive viagra ...  \n",
       "3  enron hpl actuals december teco tap enron hpl ...  \n",
       "4  looking cheap high quality software rotated na...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Joining words for tf-idf TRAIN\n",
    "df['text_joined'] = df['text_tokens'].apply(lambda x: ' '.join(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33665, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vecotrization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Td-Idf </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df[\"text_joined\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Step 1: Train-test split\n",
    "X_train, X_test, y_train_tfidf, y_test_tfidf = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Initialize and fit the vectorizer on training data\n",
    "tfidf = TfidfVectorizer(max_features=12000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Step 3: Transform the test data using the same vectorizer\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.model_selection import GridSearchCV, train_test_split,RandomizedSearchCV\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "\n",
    "# # Data Preparation\n",
    "# x = df[\"text_joined\"]  # Your text data\n",
    "# y = df[\"label\"]  # Labels\n",
    "\n",
    "# # Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ### Set up the Pipeline ###\n",
    "# # The pipeline will include the TF-IDF Vectorizer and the SVM model.\n",
    "# pipeline = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer()),  # Step 1: TF-IDF Vectorizer\n",
    "#     ('svm', SVC())                 # Step 2: SVM classifier\n",
    "# ])\n",
    "\n",
    "# # Define the parameter grid for both TF-IDF and SVM hyperparameters\n",
    "# param_grid = {\n",
    "#     'tfidf__max_features': [4000, 6000, 8000, 12000],           # TF-IDF parameters\n",
    "#     'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "#     #'svm__C': [0.1, 1, 10],                        # SVM parameters\n",
    "#     #'svm__kernel': ['linear', 'rbf']\n",
    "#     'svm__cache_size':[10240] ,\n",
    "#     'svm__max_iter':[1000]\n",
    "# }\n",
    "\n",
    "# # Set up GridSearchCV with accuracy as the scoring method\n",
    "# # grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy',n_jobs=-1)\n",
    "# random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, n_iter=10, cv=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "# # Fit the grid search on the training data\n",
    "# # grid_search.fit(X_train, y_train)\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best parameters and estimator\n",
    "# best_params = random_search.best_params_\n",
    "# # best_estimator = grid_search.best_estimator_\n",
    "# # print(\"Best parameters found by GridSearch:\", best_params)\n",
    "# print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# # # Evaluate the best model on the test data\n",
    "# # test_accuracy = best_estimator.score(X_test, y_test)\n",
    "# # print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "# # Evaluate on test data\n",
    "# best_svc = random_search.best_estimator_\n",
    "# accuracy = best_svc.score(X_test, y_test)\n",
    "# print(f\"Test Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26932\n",
      "6733\n",
      "33665\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf.shape[0])\n",
    "print(X_test_tfidf.shape[0])\n",
    "print(X_train_tfidf.shape[0] + X_test_tfidf.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Word2Vec </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Word2Vec Embeddings ###\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Initialize the data\n",
    "x= df['text_tokens']  \n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train_w2v, y_test_w2v = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Train the Word2Vec model on the training data\n",
    "word2vec_model = Word2Vec(sentences=X_train, vector_size=300, window=7, min_count=3, workers=7, sg=1)\n",
    "\n",
    "# Function to convert a sentence into its Word2Vec embeddings (average of word vectors)\n",
    "def vectorize_sentence(sentence, model):\n",
    "    words = [word for word in sentence if word in model.wv.key_to_index]  # Only words in vocab\n",
    "    if len(words) == 0:\n",
    "        return np.zeros(model.vector_size)  # Return zero vector if no words in the sentence\n",
    "    return np.mean(model.wv[words], axis=0)\n",
    "\n",
    "# Vectorize the training and testing data\n",
    "X_train_w2v = np.array([vectorize_sentence(sentence, word2vec_model) for sentence in X_train])\n",
    "X_test_w2v = np.array([vectorize_sentence(sentence, word2vec_model) for sentence in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# import gensim\n",
    "# from gensim.models import Word2Vec\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from scipy.stats import randint, uniform\n",
    "\n",
    "# # Initialize the data\n",
    "# x = df['text_tokens']  # Assume this column contains tokenized sentences (list of words per sentence)\n",
    "# y = df['label']\n",
    "\n",
    "# # Step 1: Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Define a custom transformer for Word2Vec\n",
    "# class Word2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, vector_size=100, window=5, min_count=1, sg=1, workers=6):\n",
    "#         self.vector_size = vector_size\n",
    "#         self.window = window\n",
    "#         self.min_count = min_count\n",
    "#         self.sg = sg  # Add 'sg' here to use CBOW or Skip-gram\n",
    "#         self.workers = workers\n",
    "#         self.model = None\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         # Train Word2Vec model\n",
    "#         self.model = Word2Vec(sentences=X, vector_size=self.vector_size, window=self.window, \n",
    "#                               min_count=self.min_count, sg=self.sg, workers=self.workers)\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         # Create sentence embeddings using the trained Word2Vec model\n",
    "#         return np.array([self.vectorize_sentence(sentence) for sentence in X])\n",
    "\n",
    "#     def vectorize_sentence(self, sentence):\n",
    "#         words = [word for word in sentence if word in self.model.wv.key_to_index]\n",
    "#         if len(words) == 0:\n",
    "#             return np.zeros(self.model.vector_size)  # Return zero vector if no words in the sentence\n",
    "#         return np.mean(self.model.wv[words], axis=0)\n",
    "\n",
    "#     def get_params(self, deep=True):\n",
    "#         # Required for RandomizedSearchCV\n",
    "#         return {\n",
    "#             'vector_size': self.vector_size,\n",
    "#             'window': self.window,\n",
    "#             'min_count': self.min_count,\n",
    "#             'sg': self.sg,\n",
    "#             'workers': self.workers\n",
    "#         }\n",
    "\n",
    "#     def set_params(self, **params):\n",
    "#         # Required for RandomizedSearchCV\n",
    "#         for key, value in params.items():\n",
    "#             setattr(self, key, value)\n",
    "#         return self\n",
    "\n",
    "# # Step 2: Define the pipeline with Word2Vec and RandomForestClassifier\n",
    "# pipeline = Pipeline([\n",
    "#     ('word2vec', Word2VecTransformer()),  # Custom Word2Vec transformer\n",
    "#     ('classifier', RandomForestClassifier(random_state=42))\n",
    "# ])\n",
    "\n",
    "# # Step 3: Define the parameter distributions for RandomizedSearchCV\n",
    "# w2v_param_distributions = {\n",
    "#     'word2vec__vector_size': randint(200, 400),  # Sample from a range of values\n",
    "#     'word2vec__window': randint(5, 10),\n",
    "#     'word2vec__min_count': randint(1, 5),\n",
    "#     'word2vec__sg': [0, 1],  # CBOW or Skip-gram\n",
    "#     'word2vec__workers': [8]  # Usually fixed based on hardware\n",
    "# }\n",
    "\n",
    "# # Step 4: Initialize RandomizedSearchCV with the pipeline\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     pipeline, \n",
    "#     w2v_param_distributions, \n",
    "#     cv=5, \n",
    "#     scoring='accuracy',  # Specify the scoring metric here\n",
    "#     n_jobs=-1,  # Use all available cores\n",
    "#     n_iter=10,  # Number of random combinations to try\n",
    "#     random_state=42  # For reproducibility\n",
    "# )\n",
    "\n",
    "# # Step 5: Fit RandomizedSearchCV on the training data\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# # Step 6: Access the best parameters and the best estimator\n",
    "# print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# # Step 7: Optionally, evaluate the best classifier\n",
    "# y_pred = random_search.predict(X_test)\n",
    "# print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26932\n",
      "6733\n",
      "33665\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_w2v))\n",
    "print(len(X_test_w2v))\n",
    "print(len(X_train_w2v) + len(X_test_w2v))\n",
    "print(np.count_nonzero(X_train_w2v[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ALGORITHMS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.SVM</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>OPTUNA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-17 20:34:32,413] A new study created in memory with name: no-name-f9e4b653-40f3-40e2-8d8d-0c871187cf5f\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:35:31,086] Trial 0 finished with value: 0.992039368939065 and parameters: {'C': 3.065688351901044, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.992039368939065.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:36:25,713] Trial 1 finished with value: 0.9886085075702956 and parameters: {'C': 0.447839794252027, 'kernel': 'linear'}. Best is trial 0 with value: 0.992039368939065.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:37:23,047] Trial 2 finished with value: 0.9924746743849493 and parameters: {'C': 6.610030266427657, 'kernel': 'poly', 'degree': 2}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:38:24,559] Trial 3 finished with value: 0.9838103498120844 and parameters: {'C': 1.3647530278034021, 'kernel': 'poly', 'degree': 4}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:39:06,447] Trial 4 finished with value: 0.9896013864818024 and parameters: {'C': 7.3014800729964255, 'kernel': 'linear'}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:40:06,921] Trial 5 finished with value: 0.9154441184315818 and parameters: {'C': 7.702372030004089, 'kernel': 'poly', 'degree': 4}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:41:04,509] Trial 6 finished with value: 0.9869008204980567 and parameters: {'C': 0.18538894350769572, 'kernel': 'linear'}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:41:44,726] Trial 7 finished with value: 0.9898960739030023 and parameters: {'C': 1.482928357791831, 'kernel': 'linear'}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:42:24,746] Trial 8 finished with value: 0.9894584837545126 and parameters: {'C': 6.746890259016948, 'kernel': 'linear'}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:43:24,265] Trial 9 finished with value: 0.9891946405417087 and parameters: {'C': 0.10045507503276509, 'kernel': 'rbf'}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:44:22,515] Trial 10 finished with value: 0.9910482240831648 and parameters: {'C': 0.6112546504966322, 'kernel': 'rbf'}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:45:19,343] Trial 11 finished with value: 0.9924703156675355 and parameters: {'C': 2.7255653383799108, 'kernel': 'poly', 'degree': 2}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:46:15,727] Trial 12 finished with value: 0.9921852387843705 and parameters: {'C': 3.548248780602922, 'kernel': 'poly', 'degree': 2}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:47:13,429] Trial 13 finished with value: 0.9921852387843705 and parameters: {'C': 2.7825213471059644, 'kernel': 'poly', 'degree': 2}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:48:13,304] Trial 14 finished with value: 0.9892846799884158 and parameters: {'C': 4.35351383382693, 'kernel': 'poly', 'degree': 3}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:49:17,334] Trial 15 finished with value: 0.9900014490653528 and parameters: {'C': 2.2310666946162705, 'kernel': 'poly', 'degree': 3}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:50:16,013] Trial 16 finished with value: 0.9914604139528151 and parameters: {'C': 0.9832878495855607, 'kernel': 'poly', 'degree': 2}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:51:11,844] Trial 17 finished with value: 0.9920416726957025 and parameters: {'C': 5.134211787360936, 'kernel': 'rbf'}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:52:10,576] Trial 18 finished with value: 0.988014440433213 and parameters: {'C': 9.94854107694739, 'kernel': 'poly', 'degree': 3}. Best is trial 2 with value: 0.9924746743849493.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:53:08,782] Trial 19 finished with value: 0.9926140477914555 and parameters: {'C': 2.177271758954969, 'kernel': 'poly', 'degree': 2}. Best is trial 19 with value: 0.9926140477914555.\n",
      "[I 2024-10-17 20:53:08,784] A new study created in memory with name: no-name-e8274952-89a0-447d-850a-e7e4b18e786f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'C': 2.177271758954969, 'kernel': 'poly', 'degree': 2}\n",
      "Best F1 Score for TF-IDF: 0.9926140477914555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:53:23,252] Trial 0 finished with value: 0.9904513888888888 and parameters: {'C': 1.5625324529194733, 'kernel': 'rbf'}. Best is trial 0 with value: 0.9904513888888888.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:53:43,136] Trial 1 finished with value: 0.8503600960256068 and parameters: {'C': 8.58309497772601, 'kernel': 'linear'}. Best is trial 0 with value: 0.9904513888888888.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:54:05,174] Trial 2 finished with value: 0.687849720223821 and parameters: {'C': 0.1262511815395881, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.9904513888888888.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:54:20,180] Trial 3 finished with value: 0.9916063675832127 and parameters: {'C': 3.8126686431341725, 'kernel': 'rbf'}. Best is trial 3 with value: 0.9916063675832127.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:54:37,135] Trial 4 finished with value: 0.990572878897752 and parameters: {'C': 9.120599716714715, 'kernel': 'poly', 'degree': 3}. Best is trial 3 with value: 0.9916063675832127.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:54:51,433] Trial 5 finished with value: 0.9916112236042812 and parameters: {'C': 2.7021135706577986, 'kernel': 'rbf'}. Best is trial 5 with value: 0.9916112236042812.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:55:10,452] Trial 6 finished with value: 0.9888744401098107 and parameters: {'C': 2.798617941506871, 'kernel': 'poly', 'degree': 2}. Best is trial 5 with value: 0.9916112236042812.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:55:28,357] Trial 7 finished with value: 0.9890173410404625 and parameters: {'C': 3.5749625366650806, 'kernel': 'poly', 'degree': 2}. Best is trial 5 with value: 0.9916112236042812.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:55:50,862] Trial 8 finished with value: 0.9510686164229472 and parameters: {'C': 0.3384666280110298, 'kernel': 'linear'}. Best is trial 5 with value: 0.9916112236042812.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:56:11,546] Trial 9 finished with value: 0.8485020587817691 and parameters: {'C': 0.9903523732392527, 'kernel': 'linear'}. Best is trial 5 with value: 0.9916112236042812.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:56:26,273] Trial 10 finished with value: 0.98959236773634 and parameters: {'C': 0.7739424322990701, 'kernel': 'rbf'}. Best is trial 5 with value: 0.9916112236042812.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:56:40,415] Trial 11 finished with value: 0.9914604139528151 and parameters: {'C': 3.393066391983894, 'kernel': 'rbf'}. Best is trial 5 with value: 0.9916112236042812.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:56:55,861] Trial 12 finished with value: 0.9907380607814761 and parameters: {'C': 1.991557856281956, 'kernel': 'rbf'}. Best is trial 5 with value: 0.9916112236042812.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:57:13,105] Trial 13 finished with value: 0.9923266251628783 and parameters: {'C': 5.362307882063856, 'kernel': 'rbf'}. Best is trial 13 with value: 0.9923266251628783.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:57:27,411] Trial 14 finished with value: 0.9926161864774866 and parameters: {'C': 4.756772140965641, 'kernel': 'rbf'}. Best is trial 14 with value: 0.9926161864774866.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:57:43,604] Trial 15 finished with value: 0.9924703156675355 and parameters: {'C': 5.879176368941016, 'kernel': 'rbf'}. Best is trial 14 with value: 0.9926161864774866.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:58:00,036] Trial 16 finished with value: 0.988157134604275 and parameters: {'C': 0.5077724601139127, 'kernel': 'rbf'}. Best is trial 14 with value: 0.9926161864774866.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:58:16,274] Trial 17 finished with value: 0.9924703156675355 and parameters: {'C': 6.020300352129361, 'kernel': 'rbf'}. Best is trial 14 with value: 0.9926161864774866.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:58:31,837] Trial 18 finished with value: 0.9903053103747649 and parameters: {'C': 1.588497828761285, 'kernel': 'rbf'}. Best is trial 14 with value: 0.9926161864774866.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-17 20:58:48,644] Trial 19 finished with value: 0.8503600960256068 and parameters: {'C': 6.892950730694227, 'kernel': 'linear'}. Best is trial 14 with value: 0.9926161864774866.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Word2Vec: {'C': 4.756772140965641, 'kernel': 'rbf'}\n",
      "Best F1 Score for Word2Vec: 0.9926161864774866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF SVM Test Accuracy: 0.9903\n",
      "TF-IDF SVM Test Precision: 0.9893\n",
      "TF-IDF SVM Test Recall: 0.9919\n",
      "TF-IDF SVM Test F1 Score: 0.9906\n",
      "TF-IDF SVM Test Confusion Matrix:\n",
      "[[3250   37]\n",
      " [  28 3418]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec SVM Test Accuracy: 0.9926\n",
      "Word2Vec SVM Test Precision: 0.9902\n",
      "Word2Vec SVM Test Recall: 0.9954\n",
      "Word2Vec SVM Test F1 Score: 0.9928\n",
      "Word2Vec SVM Test Confusion Matrix:\n",
      "[[3253   34]\n",
      " [  16 3430]]\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming you have already done the train-test split and vectorization:\n",
    "# X_train_tfidf, X_test_tfidf: TF-IDF vectorized train and test sets (sparse)\n",
    "# X_train_w2v, X_test_w2v: Word2Vec vectorized train and test sets\n",
    "# y_train, y_test: Corresponding labels\n",
    "\n",
    "### Objective function for Optuna ###\n",
    "def objective(trial, X_train, y_train, X_test, y_test):\n",
    "    # Suggest hyperparameters for SVM\n",
    "    C = trial.suggest_float('C', 0.1, 10.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
    "    if kernel == 'poly':\n",
    "        degree = trial.suggest_int('degree', 2, 4)\n",
    "    else:\n",
    "        degree = 3  # Default value for other kernels\n",
    "\n",
    "    # Feature scaling for Word2Vec (dense matrix)\n",
    "    if isinstance(X_train, np.ndarray):  \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Create and train SVM model\n",
    "    svm = SVC(C=C, kernel=kernel, degree=degree, random_state=42,  cache_size=10240, max_iter=2000)\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = svm.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    return f1  # Optuna will maximize this metric\n",
    "\n",
    "### Step 1: Optimize for TF-IDF ###\n",
    "def optimize_tfidf():\n",
    "    study_tfidf = optuna.create_study(direction='maximize')\n",
    "    study_tfidf.optimize(lambda trial: objective(trial, X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf), n_trials=20)\n",
    "\n",
    "    # Best hyperparameters from Optuna\n",
    "    print(\"Best parameters for TF-IDF:\", study_tfidf.best_params)\n",
    "    print(\"Best F1 Score for TF-IDF:\", study_tfidf.best_value)\n",
    "\n",
    "    return study_tfidf.best_params\n",
    "\n",
    "### Step 2: Optimize for Word2Vec ###\n",
    "def optimize_w2v():\n",
    "    study_w2v = optuna.create_study(direction='maximize')\n",
    "    study_w2v.optimize(lambda trial: objective(trial, X_train_w2v, y_train_w2v, X_test_w2v, y_test_w2v), n_trials=20)\n",
    "\n",
    "    # Best hyperparameters from Optuna\n",
    "    print(\"Best parameters for Word2Vec:\", study_w2v.best_params)\n",
    "    print(\"Best F1 Score for Word2Vec:\", study_w2v.best_value)\n",
    "\n",
    "    return study_w2v.best_params\n",
    "\n",
    "### Step 3: Run the optimization and evaluate ###\n",
    "best_params_tfidf = optimize_tfidf()  # Optimize for TF-IDF\n",
    "best_params_w2v = optimize_w2v()  # Optimize for Word2Vec\n",
    "\n",
    "### Step 4: Train and evaluate the best model for TF-IDF ###\n",
    "svm_tfidf_best = SVC(\n",
    "    C=best_params_tfidf['C'],\n",
    "    kernel=best_params_tfidf['kernel'],\n",
    "    degree=best_params_tfidf.get('degree', 3),\n",
    "    random_state=42,\n",
    "    cache_size=10240,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "svm_tfidf_best.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_pred_tfidf = svm_tfidf_best.predict(X_test_tfidf)\n",
    "print(f\"TF-IDF SVM Test Accuracy: {accuracy_score(y_test_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF SVM Test Precision: {precision_score(y_test_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF SVM Test Recall: {recall_score(y_test_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF SVM Test F1 Score: {f1_score(y_test_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF SVM Test Confusion Matrix:\\n{confusion_matrix(y_test_tfidf, y_pred_tfidf)}\")\n",
    "\n",
    "### Step 5: Train and evaluate the best model for Word2Vec ###\n",
    "svm_w2v_best = SVC(\n",
    "    C=best_params_w2v['C'],\n",
    "    kernel=best_params_w2v['kernel'],\n",
    "    degree=best_params_w2v.get('degree', 3),\n",
    "    random_state=42,\n",
    "    cache_size=10240,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "# Standardize the Word2Vec data before fitting\n",
    "scaler = StandardScaler()\n",
    "X_train_w2v_scaled = scaler.fit_transform(X_train_w2v)\n",
    "X_test_w2v_scaled = scaler.transform(X_test_w2v)\n",
    "\n",
    "# Fit the model\n",
    "svm_w2v_best.fit(X_train_w2v_scaled, y_train_w2v)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_pred_w2v = svm_w2v_best.predict(X_test_w2v_scaled)\n",
    "print(f\"Word2Vec SVM Test Accuracy: {accuracy_score(y_test_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec SVM Test Precision: {precision_score(y_test_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec SVM Test Recall: {recall_score(y_test_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec SVM Test F1 Score: {f1_score(y_test_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec SVM Test Confusion Matrix:\\n{confusion_matrix(y_test_w2v, y_pred_w2v)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-23 20:09:29,425] A new study created in memory with name: no-name-a7bab8d2-6853-4d5c-b859-abe1440c7acf\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:12:23,346] Trial 0 finished with value: 0.9901782376600998 and parameters: {'C': 1.0015972919229188, 'kernel': 'rbf'}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:14:20,551] Trial 1 finished with value: 0.9879730198245522 and parameters: {'C': 1.6536445913485804, 'kernel': 'linear'}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:16:14,404] Trial 2 finished with value: 0.9875669993436869 and parameters: {'C': 1.7272519616355446, 'kernel': 'linear'}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:19:12,555] Trial 3 finished with value: 0.9882717284669779 and parameters: {'C': 0.6866844053491354, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:22:08,688] Trial 4 finished with value: 0.9891231406994508 and parameters: {'C': 9.113444709856278, 'kernel': 'poly', 'degree': 2}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:23:57,994] Trial 5 finished with value: 0.987697359591712 and parameters: {'C': 2.9699466375201427, 'kernel': 'linear'}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:27:02,726] Trial 6 finished with value: 0.9856278350944379 and parameters: {'C': 0.13186931580702382, 'kernel': 'rbf'}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:28:50,123] Trial 7 finished with value: 0.9868832675650022 and parameters: {'C': 3.6093166624257234, 'kernel': 'linear'}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:31:37,057] Trial 8 finished with value: 0.9898529650125487 and parameters: {'C': 2.4532672976843997, 'kernel': 'rbf'}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:34:42,497] Trial 9 finished with value: 0.9828002590093818 and parameters: {'C': 0.9800666524570627, 'kernel': 'poly', 'degree': 4}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:37:45,275] Trial 10 finished with value: 0.9863382608635096 and parameters: {'C': 0.32068294574048983, 'kernel': 'rbf'}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:40:48,148] Trial 11 finished with value: 0.9874070897642742 and parameters: {'C': 0.43503967770744284, 'kernel': 'rbf'}. Best is trial 0 with value: 0.9901782376600998.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:43:38,981] Trial 12 finished with value: 0.9903534998756897 and parameters: {'C': 6.179525546807796, 'kernel': 'rbf'}. Best is trial 12 with value: 0.9903534998756897.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:46:25,447] Trial 13 finished with value: 0.9903534998756897 and parameters: {'C': 9.665837698287085, 'kernel': 'rbf'}. Best is trial 12 with value: 0.9903534998756897.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:49:13,002] Trial 14 finished with value: 0.9903534998756897 and parameters: {'C': 8.734824020394978, 'kernel': 'rbf'}. Best is trial 12 with value: 0.9903534998756897.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:52:02,411] Trial 15 finished with value: 0.9903534998756897 and parameters: {'C': 5.240940827929631, 'kernel': 'rbf'}. Best is trial 12 with value: 0.9903534998756897.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:54:53,477] Trial 16 finished with value: 0.9903534998756897 and parameters: {'C': 5.740925873271244, 'kernel': 'rbf'}. Best is trial 12 with value: 0.9903534998756897.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 20:57:44,538] Trial 17 finished with value: 0.9903534998756897 and parameters: {'C': 5.134249501496624, 'kernel': 'rbf'}. Best is trial 12 with value: 0.9903534998756897.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:00:35,987] Trial 18 finished with value: 0.9903534998756897 and parameters: {'C': 8.510772748162145, 'kernel': 'rbf'}. Best is trial 12 with value: 0.9903534998756897.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:03:45,051] Trial 19 finished with value: 0.9805318553720204 and parameters: {'C': 4.2417254576959005, 'kernel': 'poly', 'degree': 4}. Best is trial 12 with value: 0.9903534998756897.\n",
      "[I 2024-10-23 21:03:45,053] A new study created in memory with name: no-name-81bbf925-0fe7-4040-8729-b300754e02ed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'C': 6.179525546807796, 'kernel': 'rbf'}\n",
      "Best F1 Score for TF-IDF: 0.9903534998756897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:04:20,655] Trial 0 finished with value: 0.9900691356677273 and parameters: {'C': 1.561577986180466, 'kernel': 'rbf'}. Best is trial 0 with value: 0.9900691356677273.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:05:11,821] Trial 1 finished with value: 0.8120359594787672 and parameters: {'C': 0.46033845647411015, 'kernel': 'poly', 'degree': 3}. Best is trial 0 with value: 0.9900691356677273.\n",
      "[I 2024-10-23 21:06:01,425] Trial 2 finished with value: 0.9855401055766284 and parameters: {'C': 0.13919610109239242, 'kernel': 'rbf'}. Best is trial 0 with value: 0.9900691356677273.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:06:46,048] Trial 3 finished with value: 0.9623173594262031 and parameters: {'C': 0.6616713820658492, 'kernel': 'linear'}. Best is trial 0 with value: 0.9900691356677273.\n",
      "[I 2024-10-23 21:07:42,320] Trial 4 finished with value: 0.9848322450506057 and parameters: {'C': 0.10615277809280986, 'kernel': 'rbf'}. Best is trial 0 with value: 0.9900691356677273.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:08:16,301] Trial 5 finished with value: 0.9900691356677273 and parameters: {'C': 1.5491309151824846, 'kernel': 'rbf'}. Best is trial 0 with value: 0.9900691356677273.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:08:50,776] Trial 6 finished with value: 0.9906140284333261 and parameters: {'C': 2.5819294969414637, 'kernel': 'rbf'}. Best is trial 6 with value: 0.9906140284333261.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:09:30,151] Trial 7 finished with value: 0.9875978906823306 and parameters: {'C': 1.8507733800674189, 'kernel': 'poly', 'degree': 2}. Best is trial 6 with value: 0.9906140284333261.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:10:03,858] Trial 8 finished with value: 0.9908387480899581 and parameters: {'C': 5.390432491785089, 'kernel': 'rbf'}. Best is trial 8 with value: 0.9908387480899581.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:10:38,161] Trial 9 finished with value: 0.9894833964860646 and parameters: {'C': 1.0079659199633064, 'kernel': 'rbf'}. Best is trial 8 with value: 0.9908387480899581.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:11:22,206] Trial 10 finished with value: 0.927314498560459 and parameters: {'C': 9.410967228527852, 'kernel': 'linear'}. Best is trial 8 with value: 0.9908387480899581.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:11:55,224] Trial 11 finished with value: 0.9909293275440831 and parameters: {'C': 5.981838190834487, 'kernel': 'rbf'}. Best is trial 11 with value: 0.9909293275440831.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:12:28,368] Trial 12 finished with value: 0.9907882600863532 and parameters: {'C': 9.303298807345971, 'kernel': 'rbf'}. Best is trial 11 with value: 0.9909293275440831.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:13:12,268] Trial 13 finished with value: 0.927314498560459 and parameters: {'C': 4.229250380034476, 'kernel': 'linear'}. Best is trial 11 with value: 0.9909293275440831.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:13:45,608] Trial 14 finished with value: 0.9907931832402392 and parameters: {'C': 4.598652369986554, 'kernel': 'rbf'}. Best is trial 11 with value: 0.9909293275440831.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:14:34,967] Trial 15 finished with value: 0.9297759924863795 and parameters: {'C': 4.845217119090662, 'kernel': 'poly', 'degree': 4}. Best is trial 11 with value: 0.9909293275440831.\n",
      "[I 2024-10-23 21:15:16,349] Trial 16 finished with value: 0.9872421860014053 and parameters: {'C': 0.2763553951638377, 'kernel': 'rbf'}. Best is trial 11 with value: 0.9909293275440831.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:15:50,042] Trial 17 finished with value: 0.9907519563831089 and parameters: {'C': 3.048565281203452, 'kernel': 'rbf'}. Best is trial 11 with value: 0.9909293275440831.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:16:34,928] Trial 18 finished with value: 0.927314498560459 and parameters: {'C': 7.2181577345575265, 'kernel': 'linear'}. Best is trial 11 with value: 0.9909293275440831.\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2024-10-23 21:17:25,533] Trial 19 finished with value: 0.9798947982586437 and parameters: {'C': 6.053114645982823, 'kernel': 'poly', 'degree': 4}. Best is trial 11 with value: 0.9909293275440831.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Word2Vec: {'C': 5.981838190834487, 'kernel': 'rbf'}\n",
      "Best F1 Score for Word2Vec: 0.9909293275440831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF SVM Validation Accuracy: 0.9918\n",
      "TF-IDF SVM Validation Precision: 0.9873\n",
      "TF-IDF SVM Validation Recall: 0.9967\n",
      "TF-IDF SVM Validation F1 Score: 0.9920\n",
      "TF-IDF SVM Validation Confusion Matrix:\n",
      "[[2617   35]\n",
      " [   9 2726]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vatsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec SVM Validation Accuracy: 0.9913\n",
      "Word2Vec SVM Validation Precision: 0.9863\n",
      "Word2Vec SVM Validation Recall: 0.9967\n",
      "Word2Vec SVM Validation F1 Score: 0.9915\n",
      "Word2Vec SVM Validation Confusion Matrix:\n",
      "[[2614   38]\n",
      " [   9 2726]]\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Assuming you have already done the train-test split and vectorization:\n",
    "# X_train_tfidf, X_test_tfidf: TF-IDF vectorized train and test sets (sparse)\n",
    "# X_train_w2v, X_test_w2v: Word2Vec vectorized train and test sets\n",
    "# y_train, y_test: Corresponding labels\n",
    "\n",
    "# Split the training set into train/validation set\n",
    "X_train_tfidf, X_val_tfidf, y_train_tfidf, y_val_tfidf = train_test_split(\n",
    "    X_train_tfidf, y_train_tfidf, test_size=0.2, random_state=42, stratify=y_train_tfidf)\n",
    "\n",
    "X_train_w2v, X_val_w2v, y_train_w2v, y_val_w2v = train_test_split(\n",
    "    X_train_w2v, y_train_w2v, test_size=0.2, random_state=42, stratify=y_train_w2v)\n",
    "\n",
    "# Cross-validation settings\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "### Objective function for Optuna ###\n",
    "def objective(trial, X_train, y_train):\n",
    "    # Suggest hyperparameters for SVM\n",
    "    C = trial.suggest_float('C', 0.1, 10.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
    "    if kernel == 'poly':\n",
    "        degree = trial.suggest_int('degree', 2, 4)\n",
    "    else:\n",
    "        degree = 3  # Default value for other kernels\n",
    "\n",
    "    # Feature scaling for Word2Vec (dense matrix)\n",
    "    if isinstance(X_train, np.ndarray):  \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Create SVM model\n",
    "    svm = SVC(C=C, kernel=kernel, degree=degree, random_state=42, cache_size=10240, max_iter=2000)\n",
    "\n",
    "    # Cross-validation scoring\n",
    "    scores = cross_val_score(svm, X_train, y_train, cv=cv, scoring='f1')\n",
    "\n",
    "    # Return mean F1 score\n",
    "    return np.mean(scores)\n",
    "\n",
    "### Step 1: Optimize for TF-IDF ###\n",
    "def optimize_tfidf():\n",
    "    study_tfidf = optuna.create_study(direction='maximize')\n",
    "    study_tfidf.optimize(lambda trial: objective(trial, X_train_tfidf, y_train_tfidf), n_trials=20)\n",
    "\n",
    "    # Best hyperparameters from Optuna\n",
    "    print(\"Best parameters for TF-IDF:\", study_tfidf.best_params)\n",
    "    print(\"Best F1 Score for TF-IDF:\", study_tfidf.best_value)\n",
    "\n",
    "    return study_tfidf.best_params\n",
    "\n",
    "### Step 2: Optimize for Word2Vec ###\n",
    "def optimize_w2v():\n",
    "    study_w2v = optuna.create_study(direction='maximize')\n",
    "    study_w2v.optimize(lambda trial: objective(trial, X_train_w2v, y_train_w2v), n_trials=20)\n",
    "\n",
    "    # Best hyperparameters from Optuna\n",
    "    print(\"Best parameters for Word2Vec:\", study_w2v.best_params)\n",
    "    print(\"Best F1 Score for Word2Vec:\", study_w2v.best_value)\n",
    "\n",
    "    return study_w2v.best_params\n",
    "\n",
    "### Step 3: Run the optimization and evaluate ###\n",
    "best_params_tfidf = optimize_tfidf()  # Optimize for TF-IDF\n",
    "best_params_w2v = optimize_w2v()  # Optimize for Word2Vec\n",
    "\n",
    "### Step 4: Train and evaluate the best model for TF-IDF ###\n",
    "\n",
    "svm_tfidf_best = SVC(\n",
    "    C=best_params_tfidf['C'],\n",
    "    kernel=best_params_tfidf['kernel'],\n",
    "    degree=best_params_tfidf.get('degree', 3),\n",
    "    random_state=42,\n",
    "    cache_size=10240,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "# Fit the model on the train set and evaluate on the validation set\n",
    "svm_tfidf_best.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Predict and evaluate on the validation set\n",
    "y_pred_tfidf = svm_tfidf_best.predict(X_val_tfidf)\n",
    "print(f\"TF-IDF SVM Validation Accuracy: {accuracy_score(y_val_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF SVM Validation Precision: {precision_score(y_val_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF SVM Validation Recall: {recall_score(y_val_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF SVM Validation F1 Score: {f1_score(y_val_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF SVM Validation Confusion Matrix:\\n{confusion_matrix(y_val_tfidf, y_pred_tfidf)}\")\n",
    "\n",
    "### Step 5: Train and evaluate the best model for Word2Vec ###\n",
    "\n",
    "svm_w2v_best = SVC(\n",
    "    C=best_params_w2v['C'],\n",
    "    kernel=best_params_w2v['kernel'],\n",
    "    degree=best_params_w2v.get('degree', 3),\n",
    "    random_state=42,\n",
    "    cache_size=10240,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "# Standardize the Word2Vec data before fitting\n",
    "scaler = StandardScaler()\n",
    "X_train_w2v_scaled = scaler.fit_transform(X_train_w2v)\n",
    "X_val_w2v_scaled = scaler.transform(X_val_w2v)\n",
    "\n",
    "# Fit the model\n",
    "svm_w2v_best.fit(X_train_w2v_scaled, y_train_w2v)\n",
    "\n",
    "# Predict and evaluate on the validation set\n",
    "y_pred_w2v = svm_w2v_best.predict(X_val_w2v_scaled)\n",
    "print(f\"Word2Vec SVM Validation Accuracy: {accuracy_score(y_val_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec SVM Validation Precision: {precision_score(y_val_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec SVM Validation Recall: {recall_score(y_val_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec SVM Validation F1 Score: {f1_score(y_val_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec SVM Validation Confusion Matrix:\\n{confusion_matrix(y_val_w2v, y_pred_w2v)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2. Random Forest </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> OPTUNA CODE </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-17 14:59:14,855] A new study created in memory with name: no-name-185cf3b7-bbd5-4814-90f9-b8d79c84f0ba\n",
      "[I 2024-10-17 14:59:17,634] Trial 0 finished with value: 0.9684805653710248 and parameters: {'n_estimators': 180, 'max_depth': 30, 'min_samples_split': 9}. Best is trial 0 with value: 0.9684805653710248.\n",
      "[I 2024-10-17 14:59:22,726] Trial 1 finished with value: 0.9748042704626334 and parameters: {'n_estimators': 280, 'max_depth': 40, 'min_samples_split': 10}. Best is trial 1 with value: 0.9748042704626334.\n",
      "[I 2024-10-17 14:59:24,800] Trial 2 finished with value: 0.9683347469607012 and parameters: {'n_estimators': 140, 'max_depth': 30, 'min_samples_split': 6}. Best is trial 1 with value: 0.9748042704626334.\n",
      "[I 2024-10-17 14:59:28,279] Trial 3 finished with value: 0.975505553973227 and parameters: {'n_estimators': 150, 'max_depth': 40, 'min_samples_split': 7}. Best is trial 3 with value: 0.975505553973227.\n",
      "[I 2024-10-17 14:59:36,352] Trial 4 finished with value: 0.978978978978979 and parameters: {'n_estimators': 290, 'max_depth': 50, 'min_samples_split': 5}. Best is trial 4 with value: 0.978978978978979.\n",
      "[I 2024-10-17 14:59:41,554] Trial 5 finished with value: 0.9858299595141701 and parameters: {'n_estimators': 110, 'max_depth': None, 'min_samples_split': 9}. Best is trial 5 with value: 0.9858299595141701.\n",
      "[I 2024-10-17 14:59:46,339] Trial 6 finished with value: 0.9861191440138809 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 4}. Best is trial 6 with value: 0.9861191440138809.\n",
      "[I 2024-10-17 14:59:47,880] Trial 7 finished with value: 0.9197530864197531 and parameters: {'n_estimators': 270, 'max_depth': 10, 'min_samples_split': 7}. Best is trial 6 with value: 0.9861191440138809.\n",
      "[I 2024-10-17 14:59:52,286] Trial 8 finished with value: 0.9669678147939017 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 10}. Best is trial 6 with value: 0.9861191440138809.\n",
      "[I 2024-10-17 14:59:54,106] Trial 9 finished with value: 0.9529771841958821 and parameters: {'n_estimators': 180, 'max_depth': 20, 'min_samples_split': 8}. Best is trial 6 with value: 0.9861191440138809.\n",
      "[I 2024-10-17 15:00:04,645] Trial 10 finished with value: 0.986836395197454 and parameters: {'n_estimators': 230, 'max_depth': None, 'min_samples_split': 3}. Best is trial 10 with value: 0.986836395197454.\n",
      "[I 2024-10-17 15:00:15,311] Trial 11 finished with value: 0.986404396875904 and parameters: {'n_estimators': 230, 'max_depth': None, 'min_samples_split': 2}. Best is trial 10 with value: 0.986836395197454.\n",
      "[I 2024-10-17 15:00:27,604] Trial 12 finished with value: 0.986404396875904 and parameters: {'n_estimators': 230, 'max_depth': None, 'min_samples_split': 2}. Best is trial 10 with value: 0.986836395197454.\n",
      "[I 2024-10-17 15:00:39,382] Trial 13 finished with value: 0.9866898148148148 and parameters: {'n_estimators': 240, 'max_depth': None, 'min_samples_split': 2}. Best is trial 10 with value: 0.986836395197454.\n",
      "[I 2024-10-17 15:00:50,633] Trial 14 finished with value: 0.9871257051931144 and parameters: {'n_estimators': 240, 'max_depth': None, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:00:53,072] Trial 15 finished with value: 0.9540389972144847 and parameters: {'n_estimators': 250, 'max_depth': 20, 'min_samples_split': 4}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:00:54,160] Trial 16 finished with value: 0.9181294385635803 and parameters: {'n_estimators': 210, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:00:59,608] Trial 17 finished with value: 0.9782795084309803 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:01:11,900] Trial 18 finished with value: 0.9869829331790569 and parameters: {'n_estimators': 260, 'max_depth': None, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:01:23,201] Trial 19 finished with value: 0.9869640787949016 and parameters: {'n_estimators': 260, 'max_depth': None, 'min_samples_split': 5}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:01:33,318] Trial 20 finished with value: 0.9869829331790569 and parameters: {'n_estimators': 210, 'max_depth': None, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:01:43,462] Trial 21 finished with value: 0.9869829331790569 and parameters: {'n_estimators': 210, 'max_depth': None, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:01:54,909] Trial 22 finished with value: 0.9869640787949016 and parameters: {'n_estimators': 260, 'max_depth': None, 'min_samples_split': 5}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:02:03,622] Trial 23 finished with value: 0.9862617498192335 and parameters: {'n_estimators': 190, 'max_depth': None, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:02:13,201] Trial 24 finished with value: 0.9868402024584237 and parameters: {'n_estimators': 220, 'max_depth': None, 'min_samples_split': 4}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:02:19,281] Trial 25 finished with value: 0.9786929786929787 and parameters: {'n_estimators': 250, 'max_depth': 50, 'min_samples_split': 2}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:02:20,196] Trial 26 finished with value: 0.9189914163090128 and parameters: {'n_estimators': 160, 'max_depth': 10, 'min_samples_split': 6}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:02:23,149] Trial 27 finished with value: 0.9552613240418119 and parameters: {'n_estimators': 280, 'max_depth': 20, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:02:28,034] Trial 28 finished with value: 0.9752348420153715 and parameters: {'n_estimators': 240, 'max_depth': 40, 'min_samples_split': 4}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:02:30,731] Trial 29 finished with value: 0.9676690667796132 and parameters: {'n_estimators': 170, 'max_depth': 30, 'min_samples_split': 5}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:02:39,704] Trial 30 finished with value: 0.9868402024584237 and parameters: {'n_estimators': 190, 'max_depth': None, 'min_samples_split': 2}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:02:49,319] Trial 31 finished with value: 0.9869829331790569 and parameters: {'n_estimators': 210, 'max_depth': None, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:02:58,889] Trial 32 finished with value: 0.9869829331790569 and parameters: {'n_estimators': 210, 'max_depth': None, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:03:08,958] Trial 33 finished with value: 0.9869829331790569 and parameters: {'n_estimators': 220, 'max_depth': None, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:03:14,370] Trial 34 finished with value: 0.9748114415824676 and parameters: {'n_estimators': 270, 'max_depth': 40, 'min_samples_split': 4}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:03:21,025] Trial 35 finished with value: 0.985691573926868 and parameters: {'n_estimators': 130, 'max_depth': None, 'min_samples_split': 2}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:03:24,093] Trial 36 finished with value: 0.9677784058790277 and parameters: {'n_estimators': 190, 'max_depth': 30, 'min_samples_split': 6}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:03:35,142] Trial 37 finished with value: 0.9868211440984793 and parameters: {'n_estimators': 250, 'max_depth': None, 'min_samples_split': 5}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:03:42,418] Trial 38 finished with value: 0.9781334857796198 and parameters: {'n_estimators': 290, 'max_depth': 50, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:03:47,129] Trial 39 finished with value: 0.975505553973227 and parameters: {'n_estimators': 220, 'max_depth': 40, 'min_samples_split': 4}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:03:55,579] Trial 40 finished with value: 0.9862617498192335 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 6}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:04:05,076] Trial 41 finished with value: 0.9869829331790569 and parameters: {'n_estimators': 210, 'max_depth': None, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:04:15,633] Trial 42 finished with value: 0.9871257051931144 and parameters: {'n_estimators': 240, 'max_depth': None, 'min_samples_split': 3}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:04:26,586] Trial 43 finished with value: 0.9866898148148148 and parameters: {'n_estimators': 240, 'max_depth': None, 'min_samples_split': 2}. Best is trial 14 with value: 0.9871257051931144.\n",
      "[I 2024-10-17 15:04:38,207] Trial 44 finished with value: 0.9874077290490665 and parameters: {'n_estimators': 270, 'max_depth': None, 'min_samples_split': 4}. Best is trial 44 with value: 0.9874077290490665.\n",
      "[I 2024-10-17 15:04:50,767] Trial 45 finished with value: 0.9874077290490665 and parameters: {'n_estimators': 270, 'max_depth': None, 'min_samples_split': 4}. Best is trial 44 with value: 0.9874077290490665.\n",
      "[I 2024-10-17 15:04:53,618] Trial 46 finished with value: 0.9536405401642768 and parameters: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 4}. Best is trial 44 with value: 0.9874077290490665.\n",
      "[I 2024-10-17 15:04:55,035] Trial 47 finished with value: 0.919382964453387 and parameters: {'n_estimators': 280, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 44 with value: 0.9874077290490665.\n",
      "[I 2024-10-17 15:04:59,002] Trial 48 finished with value: 0.9664315937940762 and parameters: {'n_estimators': 270, 'max_depth': 30, 'min_samples_split': 8}. Best is trial 44 with value: 0.9874077290490665.\n",
      "[I 2024-10-17 15:05:11,359] Trial 49 finished with value: 0.9874077290490665 and parameters: {'n_estimators': 290, 'max_depth': None, 'min_samples_split': 4}. Best is trial 44 with value: 0.9874077290490665.\n",
      "[I 2024-10-17 15:05:11,367] A new study created in memory with name: no-name-751b8492-b7e9-4e89-8225-1ed519fbee29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'n_estimators': 270, 'max_depth': None, 'min_samples_split': 4}\n",
      "Best F1 Score for TF-IDF: 0.9874077290490665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-17 15:05:24,904] Trial 0 finished with value: 0.9862458375561025 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 9}. Best is trial 0 with value: 0.9862458375561025.\n",
      "[I 2024-10-17 15:05:43,229] Trial 1 finished with value: 0.987385819921705 and parameters: {'n_estimators': 190, 'max_depth': 20, 'min_samples_split': 7}. Best is trial 1 with value: 0.987385819921705.\n",
      "[I 2024-10-17 15:06:06,291] Trial 2 finished with value: 0.9879587987813724 and parameters: {'n_estimators': 270, 'max_depth': 50, 'min_samples_split': 2}. Best is trial 2 with value: 0.9879587987813724.\n",
      "[I 2024-10-17 15:06:15,871] Trial 3 finished with value: 0.9873748367435786 and parameters: {'n_estimators': 120, 'max_depth': 50, 'min_samples_split': 4}. Best is trial 2 with value: 0.9879587987813724.\n",
      "[I 2024-10-17 15:06:34,657] Trial 4 finished with value: 0.9879657822241554 and parameters: {'n_estimators': 230, 'max_depth': 50, 'min_samples_split': 9}. Best is trial 4 with value: 0.9879657822241554.\n",
      "[I 2024-10-17 15:06:46,353] Trial 5 finished with value: 0.9873931314302276 and parameters: {'n_estimators': 150, 'max_depth': 20, 'min_samples_split': 10}. Best is trial 4 with value: 0.9879657822241554.\n",
      "[I 2024-10-17 15:06:57,087] Trial 6 finished with value: 0.9863965267727931 and parameters: {'n_estimators': 190, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 4 with value: 0.9879657822241554.\n",
      "[I 2024-10-17 15:07:08,101] Trial 7 finished with value: 0.9880986937590711 and parameters: {'n_estimators': 140, 'max_depth': 30, 'min_samples_split': 2}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:07:30,860] Trial 8 finished with value: 0.9875326181501884 and parameters: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 10}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:07:50,644] Trial 9 finished with value: 0.9878190255220418 and parameters: {'n_estimators': 270, 'max_depth': 20, 'min_samples_split': 7}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:07:58,239] Trial 10 finished with value: 0.9876614893308172 and parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:08:16,661] Trial 11 finished with value: 0.987385819921705 and parameters: {'n_estimators': 230, 'max_depth': 30, 'min_samples_split': 5}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:08:28,968] Trial 12 finished with value: 0.9878154917319408 and parameters: {'n_estimators': 150, 'max_depth': 40, 'min_samples_split': 4}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:08:47,793] Trial 13 finished with value: 0.9878225572629747 and parameters: {'n_estimators': 230, 'max_depth': 30, 'min_samples_split': 6}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:09:00,422] Trial 14 finished with value: 0.987962291515591 and parameters: {'n_estimators': 160, 'max_depth': 50, 'min_samples_split': 3}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:09:18,930] Trial 15 finished with value: 0.9876650703816572 and parameters: {'n_estimators': 240, 'max_depth': None, 'min_samples_split': 8}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:09:31,457] Trial 16 finished with value: 0.9870958387704799 and parameters: {'n_estimators': 170, 'max_depth': 40, 'min_samples_split': 5}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:09:40,420] Trial 17 finished with value: 0.9878225572629747 and parameters: {'n_estimators': 120, 'max_depth': 50, 'min_samples_split': 9}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:09:59,182] Trial 18 finished with value: 0.987385819921705 and parameters: {'n_estimators': 260, 'max_depth': 30, 'min_samples_split': 6}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:10:15,237] Trial 19 finished with value: 0.9878190255220418 and parameters: {'n_estimators': 220, 'max_depth': 50, 'min_samples_split': 3}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:10:23,968] Trial 20 finished with value: 0.9870883505005078 and parameters: {'n_estimators': 120, 'max_depth': 30, 'min_samples_split': 7}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:10:36,345] Trial 21 finished with value: 0.987962291515591 and parameters: {'n_estimators': 160, 'max_depth': 50, 'min_samples_split': 3}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:10:49,378] Trial 22 finished with value: 0.9878190255220418 and parameters: {'n_estimators': 170, 'max_depth': 50, 'min_samples_split': 3}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:10:59,767] Trial 23 finished with value: 0.9880986937590711 and parameters: {'n_estimators': 140, 'max_depth': 50, 'min_samples_split': 2}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:11:10,373] Trial 24 finished with value: 0.9880986937590711 and parameters: {'n_estimators': 140, 'max_depth': 50, 'min_samples_split': 2}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:11:20,759] Trial 25 finished with value: 0.9880986937590711 and parameters: {'n_estimators': 140, 'max_depth': 40, 'min_samples_split': 2}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:11:26,086] Trial 26 finished with value: 0.9863847045191193 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:11:36,212] Trial 27 finished with value: 0.9876614893308172 and parameters: {'n_estimators': 130, 'max_depth': None, 'min_samples_split': 4}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:11:47,900] Trial 28 finished with value: 0.9880986937590711 and parameters: {'n_estimators': 140, 'max_depth': 30, 'min_samples_split': 2}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:11:59,187] Trial 29 finished with value: 0.9863886475528526 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:12:11,671] Trial 30 finished with value: 0.9876650703816572 and parameters: {'n_estimators': 180, 'max_depth': 50, 'min_samples_split': 4}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:12:21,074] Trial 31 finished with value: 0.9880986937590711 and parameters: {'n_estimators': 140, 'max_depth': 40, 'min_samples_split': 2}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:12:28,522] Trial 32 finished with value: 0.9876650703816572 and parameters: {'n_estimators': 110, 'max_depth': 40, 'min_samples_split': 2}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:12:38,451] Trial 33 finished with value: 0.9876722262509064 and parameters: {'n_estimators': 140, 'max_depth': 40, 'min_samples_split': 3}. Best is trial 7 with value: 0.9880986937590711.\n",
      "[I 2024-10-17 15:12:47,318] Trial 34 finished with value: 0.9882455376578145 and parameters: {'n_estimators': 130, 'max_depth': 40, 'min_samples_split': 2}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:12:56,105] Trial 35 finished with value: 0.9882455376578145 and parameters: {'n_estimators': 130, 'max_depth': 50, 'min_samples_split': 2}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:13:04,017] Trial 36 finished with value: 0.9865119651921682 and parameters: {'n_estimators': 110, 'max_depth': 20, 'min_samples_split': 5}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:13:12,818] Trial 37 finished with value: 0.9876614893308172 and parameters: {'n_estimators': 130, 'max_depth': 50, 'min_samples_split': 4}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:13:25,017] Trial 38 finished with value: 0.9876722262509064 and parameters: {'n_estimators': 180, 'max_depth': 50, 'min_samples_split': 3}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:13:36,521] Trial 39 finished with value: 0.9879553040197359 and parameters: {'n_estimators': 160, 'max_depth': 20, 'min_samples_split': 2}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:13:42,602] Trial 40 finished with value: 0.9852302345786272 and parameters: {'n_estimators': 120, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:13:51,742] Trial 41 finished with value: 0.9882455376578145 and parameters: {'n_estimators': 130, 'max_depth': 50, 'min_samples_split': 2}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:14:00,971] Trial 42 finished with value: 0.9882455376578145 and parameters: {'n_estimators': 130, 'max_depth': 50, 'min_samples_split': 2}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:14:08,776] Trial 43 finished with value: 0.9876650703816572 and parameters: {'n_estimators': 110, 'max_depth': 50, 'min_samples_split': 2}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:14:19,037] Trial 44 finished with value: 0.9876722262509064 and parameters: {'n_estimators': 150, 'max_depth': 30, 'min_samples_split': 3}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:14:28,014] Trial 45 finished with value: 0.9882455376578145 and parameters: {'n_estimators': 130, 'max_depth': None, 'min_samples_split': 2}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:14:36,901] Trial 46 finished with value: 0.9882455376578145 and parameters: {'n_estimators': 130, 'max_depth': None, 'min_samples_split': 2}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:14:43,810] Trial 47 finished with value: 0.9876686493544176 and parameters: {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 4}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:14:53,775] Trial 48 finished with value: 0.9876722262509064 and parameters: {'n_estimators': 150, 'max_depth': None, 'min_samples_split': 3}. Best is trial 34 with value: 0.9882455376578145.\n",
      "[I 2024-10-17 15:15:02,882] Trial 49 finished with value: 0.9882455376578145 and parameters: {'n_estimators': 130, 'max_depth': None, 'min_samples_split': 2}. Best is trial 34 with value: 0.9882455376578145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Word2Vec: {'n_estimators': 130, 'max_depth': 40, 'min_samples_split': 2}\n",
      "Best F1 Score for Word2Vec: 0.9882455376578145\n",
      "TF-IDF Random Forest Test Accuracy: 0.9871\n",
      "TF-IDF Random Forest Test Precision: 0.9805\n",
      "TF-IDF Random Forest Test Recall: 0.9945\n",
      "TF-IDF Random Forest Test F1 Score: 0.9874\n",
      "TF-IDF Random Forest Test Confusion Matrix:\n",
      "[[3246   68]\n",
      " [  19 3411]]\n",
      "Word2Vec Random Forest Test Accuracy: 0.9880\n",
      "Word2Vec Random Forest Test Precision: 0.9838\n",
      "Word2Vec Random Forest Test Recall: 0.9927\n",
      "Word2Vec Random Forest Test F1 Score: 0.9882\n",
      "Word2Vec Random Forest Test Confusion Matrix:\n",
      "[[3258   56]\n",
      " [  25 3405]]\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming you have already done the train-test split and vectorization:\n",
    "# X_train_tfidf, X_test_tfidf: TF-IDF vectorized train and test sets\n",
    "# X_train_w2v, X_test_w2v: Word2Vec vectorized train and test sets\n",
    "# y_train, y_test: Corresponding labels\n",
    "\n",
    "### Objective function for Optuna ###\n",
    "def objective(trial, X_train, y_train, X_test, y_test):\n",
    "    # Suggest hyperparameters to optimize\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100,300, step=10)\n",
    "    max_depth = trial.suggest_categorical('max_depth', [None, 10, 20, 30, 40, 50])\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    \n",
    "    # Define the model with the suggested hyperparameters\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    # Calculate the F1 score (can also be other metrics if needed)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    return f1  # Optuna will maximize this metric\n",
    "\n",
    "### Step 1: Optimize for TF-IDF ###\n",
    "def optimize_tfidf():\n",
    "    study_tfidf = optuna.create_study(direction='maximize')\n",
    "    study_tfidf.optimize(lambda trial: objective(trial, X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf), n_trials=50)\n",
    "    \n",
    "    # Best hyperparameters from Optuna\n",
    "    print(\"Best parameters for TF-IDF:\", study_tfidf.best_params)\n",
    "    print(\"Best F1 Score for TF-IDF:\", study_tfidf.best_value)\n",
    "\n",
    "    return study_tfidf.best_params\n",
    "\n",
    "### Step 2: Optimize for Word2Vec ###\n",
    "def optimize_w2v():\n",
    "    study_w2v = optuna.create_study(direction='maximize')\n",
    "    study_w2v.optimize(lambda trial: objective(trial, X_train_w2v, y_train_w2v, X_test_w2v, y_test_w2v), n_trials=50)\n",
    "    \n",
    "    # Best hyperparameters from Optuna\n",
    "    print(\"Best parameters for Word2Vec:\", study_w2v.best_params)\n",
    "    print(\"Best F1 Score for Word2Vec:\", study_w2v.best_value)\n",
    "\n",
    "    return study_w2v.best_params\n",
    "\n",
    "### Step 3: Run the optimization and evaluate ###\n",
    "best_params_tfidf = optimize_tfidf()  # Optimize for TF-IDF\n",
    "best_params_w2v = optimize_w2v()  # Optimize for Word2Vec\n",
    "\n",
    "### Step 4: Train and evaluate the best model for TF-IDF ###\n",
    "rf_tfidf_best = RandomForestClassifier(\n",
    "    n_estimators=best_params_tfidf['n_estimators'],\n",
    "    max_depth=best_params_tfidf['max_depth'],\n",
    "    min_samples_split=best_params_tfidf['min_samples_split'],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_tfidf_best.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_pred_tfidf = rf_tfidf_best.predict(X_test_tfidf)\n",
    "print(f\"TF-IDF Random Forest Test Accuracy: {accuracy_score(y_test_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF Random Forest Test Precision: {precision_score(y_test_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF Random Forest Test Recall: {recall_score(y_test_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF Random Forest Test F1 Score: {f1_score(y_test_tfidf, y_pred_tfidf):.4f}\")\n",
    "print(f\"TF-IDF Random Forest Test Confusion Matrix:\\n{confusion_matrix(y_test_tfidf, y_pred_tfidf)}\")\n",
    "\n",
    "### Step 5: Train and evaluate the best model for Word2Vec ###\n",
    "rf_w2v_best = RandomForestClassifier(\n",
    "    n_estimators=best_params_w2v['n_estimators'],\n",
    "    max_depth=best_params_w2v['max_depth'],\n",
    "    min_samples_split=best_params_w2v['min_samples_split'],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_w2v_best.fit(X_train_w2v, y_train_w2v)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_pred_w2v = rf_w2v_best.predict(X_test_w2v)\n",
    "print(f\"Word2Vec Random Forest Test Accuracy: {accuracy_score(y_test_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec Random Forest Test Precision: {precision_score(y_test_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec Random Forest Test Recall: {recall_score(y_test_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec Random Forest Test F1 Score: {f1_score(y_test_w2v, y_pred_w2v):.4f}\")\n",
    "print(f\"Word2Vec Random Forest Test Confusion Matrix:\\n{confusion_matrix(y_test_w2v, y_pred_w2v)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
