{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m venv myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !myenv\\Scripts\\activate.ps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# # Loading the dataset from Hugging Face\n",
    "dataset = load_dataset(\"SetFit/enron_spam\")\n",
    "\n",
    "# # Convert the training set to a Pandas DataFrame\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "test=pd.DataFrame(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33214</td>\n",
       "      <td>any software just for 15 $ - 99 $ understandin...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>any software just for 15 $ - 99 $</td>\n",
       "      <td>understanding oem software\\nlead me not into t...</td>\n",
       "      <td>2005-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11929</td>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>19 th , 2 : 00 pm edt\\nperspective on ferc reg...</td>\n",
       "      <td>2001-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19784</td>\n",
       "      <td>wanted to try ci 4 lis but thought it was way ...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>wanted to try ci 4 lis but thought it was way ...</td>\n",
       "      <td>viagra at $ 1 . 12 per dose\\nready to boost yo...</td>\n",
       "      <td>2004-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2209</td>\n",
       "      <td>enron / hpl actuals for december 11 , 2000 tec...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>enron / hpl actuals for december 11 , 2000</td>\n",
       "      <td>teco tap 30 . 000 / enron ; 120 . 000 / hpl ga...</td>\n",
       "      <td>2000-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15880</td>\n",
       "      <td>looking for cheap high - quality software ? ro...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>looking for cheap high - quality software ? ro...</td>\n",
       "      <td>water past also , burn , course . gave country...</td>\n",
       "      <td>2005-02-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   message_id                                               text  label  \\\n",
       "0       33214  any software just for 15 $ - 99 $ understandin...      1   \n",
       "1       11929  perspective on ferc regulatory action client c...      0   \n",
       "2       19784  wanted to try ci 4 lis but thought it was way ...      1   \n",
       "3        2209  enron / hpl actuals for december 11 , 2000 tec...      0   \n",
       "4       15880  looking for cheap high - quality software ? ro...      1   \n",
       "\n",
       "  label_text                                            subject  \\\n",
       "0       spam                  any software just for 15 $ - 99 $   \n",
       "1        ham  perspective on ferc regulatory action client c...   \n",
       "2       spam  wanted to try ci 4 lis but thought it was way ...   \n",
       "3        ham         enron / hpl actuals for december 11 , 2000   \n",
       "4       spam  looking for cheap high - quality software ? ro...   \n",
       "\n",
       "                                             message       date  \n",
       "0  understanding oem software\\nlead me not into t... 2005-06-18  \n",
       "1  19 th , 2 : 00 pm edt\\nperspective on ferc reg... 2001-06-19  \n",
       "2  viagra at $ 1 . 12 per dose\\nready to boost yo... 2004-09-11  \n",
       "3  teco tap 30 . 000 / enron ; 120 . 000 / hpl ga... 2000-12-12  \n",
       "4  water past also , burn , course . gave country... 2005-02-13  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=df\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31329</td>\n",
       "      <td>expande tu imagen ! ! ! ! ! ! ! ! ! si no pued...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>expande tu imagen ! ! ! ! ! ! ! ! !</td>\n",
       "      <td>si no puede ver este mail , entre a : http : /...</td>\n",
       "      <td>2005-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3969</td>\n",
       "      <td>paliourg learning for life enlarge your member...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>paliourg learning for life</td>\n",
       "      <td>enlarge your member\\nzenextend enlargement pil...</td>\n",
       "      <td>2004-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27070</td>\n",
       "      <td>cure premature ejaculation hello ,\\ndid you ej...</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>cure premature ejaculation</td>\n",
       "      <td>hello ,\\ndid you ejaculate before or within a ...</td>\n",
       "      <td>2005-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2779</td>\n",
       "      <td>re : noms / actual flow for 3 / 19 / 01 we agr...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>re : noms / actual flow for 3 / 19 / 01</td>\n",
       "      <td>we agree\\n\" eileen ponton \" on 03 / 20 / 2001 ...</td>\n",
       "      <td>2001-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2949</td>\n",
       "      <td>ehronline web address change this message is i...</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>ehronline web address change</td>\n",
       "      <td>this message is intended for ehronline users o...</td>\n",
       "      <td>2001-03-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   message_id                                               text  label  \\\n",
       "0       31329  expande tu imagen ! ! ! ! ! ! ! ! ! si no pued...      1   \n",
       "1        3969  paliourg learning for life enlarge your member...      1   \n",
       "2       27070  cure premature ejaculation hello ,\\ndid you ej...      1   \n",
       "3        2779  re : noms / actual flow for 3 / 19 / 01 we agr...      0   \n",
       "4        2949  ehronline web address change this message is i...      0   \n",
       "\n",
       "  label_text                                  subject  \\\n",
       "0       spam      expande tu imagen ! ! ! ! ! ! ! ! !   \n",
       "1       spam               paliourg learning for life   \n",
       "2       spam               cure premature ejaculation   \n",
       "3        ham  re : noms / actual flow for 3 / 19 / 01   \n",
       "4        ham             ehronline web address change   \n",
       "\n",
       "                                             message       date  \n",
       "0  si no puede ver este mail , entre a : http : /... 2005-01-19  \n",
       "1  enlarge your member\\nzenextend enlargement pil... 2004-05-06  \n",
       "2  hello ,\\ndid you ejaculate before or within a ... 2005-07-17  \n",
       "3  we agree\\n\" eileen ponton \" on 03 / 20 / 2001 ... 2001-03-20  \n",
       "4  this message is intended for ehronline users o... 2001-03-30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=test\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33716, 7)\n",
      "33716\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train_data, test_data], ignore_index=True)\n",
    "print(df.shape)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [message_id, text, label, label_text, subject, message, date]\n",
      "Index: []\n",
      "Cleaned DataFrame shape: (33665, 7)\n"
     ]
    }
   ],
   "source": [
    "# # df\n",
    "# Drop rows where 'text_joined' is empty\n",
    "df = df[df['text'].str.len() > 0]\n",
    "\n",
    "print(df[df['text'].str.len() == 0])  # Find any empty texts\n",
    "\n",
    "\n",
    "# Optionally, reset the index if needed\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the shape of the cleaned DataFrame to verify\n",
    "print(f'Cleaned DataFrame shape: {df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [message_id, text, label, label_text, subject, message, date]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df[df['text'].str.len() == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message_id    0\n",
      "text          0\n",
      "label         0\n",
      "label_text    0\n",
      "subject       0\n",
      "message       0\n",
      "date          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    17120\n",
      "0    16545\n",
      "Name: count, dtype: int64\n",
      "Percentage of ham (0): 49.15%\n",
      "Percentage of spam (1): 50.85%\n"
     ]
    }
   ],
   "source": [
    "counts = df['label'].value_counts()\n",
    "print(counts)\n",
    "\n",
    "# Calculate percentages\n",
    "percentages = (counts / len(df)) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Percentage of ham (0): {percentages.get(0, 0):.2f}%\")\n",
    "print(f\"Percentage of spam (1): {percentages.get(1, 0):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for 15 $ - 99 $ understandin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci 4 lis but thought it was way ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron / hpl actuals for december 11 , 2000 tec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high - quality software ? ro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  any software just for 15 $ - 99 $ understandin...      1\n",
       "1  perspective on ferc regulatory action client c...      0\n",
       "2  wanted to try ci 4 lis but thought it was way ...      1\n",
       "3  enron / hpl actuals for december 11 , 2000 tec...      0\n",
       "4  looking for cheap high - quality software ? ro...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Preprocessing\n",
    "# ## Droping columns for train and test dataset.\n",
    "# train_data= train_data.drop(columns=['message_id', 'label_text', 'date', 'subject','message'])\n",
    "df =df.drop(columns=['message_id', 'label_text', 'date', 'message', 'subject'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for 15 $ - 99 $ understandin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci 4 lis but thought it was way ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron / hpl actuals for december 11 , 2000 tec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high - quality software ? ro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  any software just for 15 $ - 99 $ understandin...      1\n",
       "1  perspective on ferc regulatory action client c...      0\n",
       "2  wanted to try ci 4 lis but thought it was way ...      1\n",
       "3  enron / hpl actuals for december 11 , 2000 tec...      0\n",
       "4  looking for cheap high - quality software ? ro...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Text Normalization\n",
    "# ## Lowercasing\n",
    "# # List of columns to apply lowercasing\n",
    "columns_to_lower = ['text']  # Replace with your actual column names\n",
    "\n",
    "# # Apply str.lower() to each column in the list\n",
    "# # train_data[columns_to_lower] = train_data[columns_to_lower].apply(lambda x: x.str.lower())\n",
    "df[columns_to_lower] = df[columns_to_lower].apply(lambda x: x.str.lower())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for 15   99  understanding o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci 4 lis but thought it was way ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december 11  2000 teco ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33660</th>\n",
       "      <td>re  book notes vince  look forward to meeting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33661</th>\n",
       "      <td>rollout schedule for unify real  time deal  pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33662</th>\n",
       "      <td>anshuman shrivastava sandeep  vince has asked ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33663</th>\n",
       "      <td>re  good morning john \\ni shall see christie t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33664</th>\n",
       "      <td>customer meeting ngts  whose main headquarters...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      any software just for 15   99  understanding o...      1\n",
       "1      perspective on ferc regulatory action client c...      0\n",
       "2      wanted to try ci 4 lis but thought it was way ...      1\n",
       "3      enron  hpl actuals for december 11  2000 teco ...      0\n",
       "4      looking for cheap high  quality software  rota...      1\n",
       "...                                                  ...    ...\n",
       "33660  re  book notes vince  look forward to meeting ...      0\n",
       "33661  rollout schedule for unify real  time deal  pa...      0\n",
       "33662  anshuman shrivastava sandeep  vince has asked ...      0\n",
       "33663  re  good morning john \\ni shall see christie t...      0\n",
       "33664  customer meeting ngts  whose main headquarters...      0\n",
       "\n",
       "[33665 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Removing punctutaitons \n",
    "import string\n",
    "df['text'] = df['text'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33660</th>\n",
       "      <td>re  book notes vince  look forward to meeting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33661</th>\n",
       "      <td>rollout schedule for unify real  time deal  pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33662</th>\n",
       "      <td>anshuman shrivastava sandeep  vince has asked ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33663</th>\n",
       "      <td>re  good morning john \\ni shall see christie t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33664</th>\n",
       "      <td>customer meeting ngts  whose main headquarters...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      any software just for      understanding oem s...      1\n",
       "1      perspective on ferc regulatory action client c...      0\n",
       "2      wanted to try ci  lis but thought it was way t...      1\n",
       "3      enron  hpl actuals for december    teco tap   ...      0\n",
       "4      looking for cheap high  quality software  rota...      1\n",
       "...                                                  ...    ...\n",
       "33660  re  book notes vince  look forward to meeting ...      0\n",
       "33661  rollout schedule for unify real  time deal  pa...      0\n",
       "33662  anshuman shrivastava sandeep  vince has asked ...      0\n",
       "33663  re  good morning john \\ni shall see christie t...      0\n",
       "33664  customer meeting ngts  whose main headquarters...      0\n",
       "\n",
       "[33665 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # # Removing numbers and special charectors\n",
    "df['text'] = df['text'].str.replace(r'\\d+', '', regex=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33660</th>\n",
       "      <td>re  book notes vince  look forward to meeting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33661</th>\n",
       "      <td>rollout schedule for unify real  time deal  pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33662</th>\n",
       "      <td>anshuman shrivastava sandeep  vince has asked ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33663</th>\n",
       "      <td>re  good morning john \\ni shall see christie t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33664</th>\n",
       "      <td>customer meeting ngts  whose main headquarters...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      any software just for      understanding oem s...      1\n",
       "1      perspective on ferc regulatory action client c...      0\n",
       "2      wanted to try ci  lis but thought it was way t...      1\n",
       "3      enron  hpl actuals for december    teco tap   ...      0\n",
       "4      looking for cheap high  quality software  rota...      1\n",
       "...                                                  ...    ...\n",
       "33660  re  book notes vince  look forward to meeting ...      0\n",
       "33661  rollout schedule for unify real  time deal  pa...      0\n",
       "33662  anshuman shrivastava sandeep  vince has asked ...      0\n",
       "33663  re  good morning john \\ni shall see christie t...      0\n",
       "33664  customer meeting ngts  whose main headquarters...      0\n",
       "\n",
       "[33665 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # #Removing WHite spaces\n",
    "df['text'] = df['text'].str.strip()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk \n",
    "# # nltk.download('punkt_tab')\n",
    "# # nltk.download('wordnet')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[any, software, just, for, understanding, oem,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[perspective, on, ferc, regulatory, action, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wanted, to, try, ci, lis, but, thought, it, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[enron, hpl, actuals, for, december, teco, tap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "      <td>[looking, for, cheap, high, quality, software,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  any software just for      understanding oem s...      1   \n",
       "1  perspective on ferc regulatory action client c...      0   \n",
       "2  wanted to try ci  lis but thought it was way t...      1   \n",
       "3  enron  hpl actuals for december    teco tap   ...      0   \n",
       "4  looking for cheap high  quality software  rota...      1   \n",
       "\n",
       "                                         text_tokens  \n",
       "0  [any, software, just, for, understanding, oem,...  \n",
       "1  [perspective, on, ferc, regulatory, action, cl...  \n",
       "2  [wanted, to, try, ci, lis, but, thought, it, w...  \n",
       "3  [enron, hpl, actuals, for, december, teco, tap...  \n",
       "4  [looking, for, cheap, high, quality, software,...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenization \n",
    "from nltk.tokenize import word_tokenize\n",
    "df['text_tokens'] = df['text'].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33665, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[software, understanding, oem, software, lead,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[perspective, ferc, regulatory, action, client...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wanted, try, ci, lis, thought, way, expensive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[enron, hpl, actuals, december, teco, tap, enr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "      <td>[looking, cheap, high, quality, software, rota...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  any software just for      understanding oem s...      1   \n",
       "1  perspective on ferc regulatory action client c...      0   \n",
       "2  wanted to try ci  lis but thought it was way t...      1   \n",
       "3  enron  hpl actuals for december    teco tap   ...      0   \n",
       "4  looking for cheap high  quality software  rota...      1   \n",
       "\n",
       "                                         text_tokens  \n",
       "0  [software, understanding, oem, software, lead,...  \n",
       "1  [perspective, ferc, regulatory, action, client...  \n",
       "2  [wanted, try, ci, lis, thought, way, expensive...  \n",
       "3  [enron, hpl, actuals, december, teco, tap, enr...  \n",
       "4  [looking, cheap, high, quality, software, rota...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STOPWORDS REMOVAL \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['text_tokens'] = df['text_tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33665, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[software, understanding, oem, software, lead,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[perspective, ferc, regulatory, action, client...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wanted, try, ci, li, thought, way, expensive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[enron, hpl, actuals, december, teco, tap, enr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "      <td>[looking, cheap, high, quality, software, rota...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  any software just for      understanding oem s...      1   \n",
       "1  perspective on ferc regulatory action client c...      0   \n",
       "2  wanted to try ci  lis but thought it was way t...      1   \n",
       "3  enron  hpl actuals for december    teco tap   ...      0   \n",
       "4  looking for cheap high  quality software  rota...      1   \n",
       "\n",
       "                                         text_tokens  \n",
       "0  [software, understanding, oem, software, lead,...  \n",
       "1  [perspective, ferc, regulatory, action, client...  \n",
       "2  [wanted, try, ci, li, thought, way, expensive,...  \n",
       "3  [enron, hpl, actuals, december, teco, tap, enr...  \n",
       "4  [looking, cheap, high, quality, software, rota...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lemmatization \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['text_tokens'] = df['text_tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33665, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>any software just for      understanding oem s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[software, understanding, oem, software, lead,...</td>\n",
       "      <td>software understanding oem software lead tempt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perspective on ferc regulatory action client c...</td>\n",
       "      <td>0</td>\n",
       "      <td>[perspective, ferc, regulatory, action, client...</td>\n",
       "      <td>perspective ferc regulatory action client conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wanted to try ci  lis but thought it was way t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[wanted, try, ci, li, thought, way, expensive,...</td>\n",
       "      <td>wanted try ci li thought way expensive viagra ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enron  hpl actuals for december    teco tap   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[enron, hpl, actuals, december, teco, tap, enr...</td>\n",
       "      <td>enron hpl actuals december teco tap enron hpl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>looking for cheap high  quality software  rota...</td>\n",
       "      <td>1</td>\n",
       "      <td>[looking, cheap, high, quality, software, rota...</td>\n",
       "      <td>looking cheap high quality software rotated na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  any software just for      understanding oem s...      1   \n",
       "1  perspective on ferc regulatory action client c...      0   \n",
       "2  wanted to try ci  lis but thought it was way t...      1   \n",
       "3  enron  hpl actuals for december    teco tap   ...      0   \n",
       "4  looking for cheap high  quality software  rota...      1   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [software, understanding, oem, software, lead,...   \n",
       "1  [perspective, ferc, regulatory, action, client...   \n",
       "2  [wanted, try, ci, li, thought, way, expensive,...   \n",
       "3  [enron, hpl, actuals, december, teco, tap, enr...   \n",
       "4  [looking, cheap, high, quality, software, rota...   \n",
       "\n",
       "                                         text_joined  \n",
       "0  software understanding oem software lead tempt...  \n",
       "1  perspective ferc regulatory action client conf...  \n",
       "2  wanted try ci li thought way expensive viagra ...  \n",
       "3  enron hpl actuals december teco tap enron hpl ...  \n",
       "4  looking cheap high quality software rotated na...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Joining words for tf-idf TRAIN\n",
    "df['text_joined'] = df['text_tokens'].apply(lambda x: ' '.join(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33665, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      text  label text_tokens text_joined\n",
      "9633            1          []            \n",
      "10544           1          []            \n",
      "24369           1          []            \n"
     ]
    }
   ],
   "source": [
    "print(df[df['text'].str.len() == 0])  # Find any empty texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Vecotrization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Td-Idf </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df[\"text_joined\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Step 1: Train-test split\n",
    "X_train, X_test, y_train_tfidf, y_test_tfidf = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Initialize and fit the vectorizer on training data\n",
    "tfidf = TfidfVectorizer(max_features=12000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Step 3: Transform the test data using the same vectorizer\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26972\n",
      "6744\n",
      "33716\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf.shape[0])\n",
    "print(X_test_tfidf.shape[0])\n",
    "print(X_train_tfidf.shape[0] + X_test_tfidf.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Word2Vec </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Word2Vec Embeddings ###\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the data\n",
    "x= df['text_tokens']  \n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train_w2v, y_test_w2v = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Train the Word2Vec model on the training data\n",
    "word2vec_model = Word2Vec(sentences=X_train, vector_size=400, window=10, min_count=1, workers=8, sg=1)\n",
    "\n",
    "# Function to convert a sentence into its Word2Vec embeddings (average of word vectors)\n",
    "def vectorize_sentence(sentence, model):\n",
    "    words = [word for word in sentence if word in model.wv.key_to_index]  # Only words in vocab\n",
    "    if len(words) == 0:\n",
    "        return np.zeros(model.vector_size)  # Return zero vector if no words in the sentence\n",
    "    return np.mean(model.wv[words], axis=0)\n",
    "\n",
    "# Vectorize the training and testing data\n",
    "X_train_w2v = np.array([vectorize_sentence(sentence, word2vec_model) for sentence in X_train])\n",
    "X_test_w2v = np.array([vectorize_sentence(sentence, word2vec_model) for sentence in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26972\n",
      "6744\n",
      "33716\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_w2v))\n",
    "print(len(X_test_w2v))\n",
    "print(len(X_train_w2v) + len(X_test_w2v))\n",
    "print(np.count_nonzero(X_train_w2v[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ALGORITHMS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1. BERT</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text, label, text_tokens, text_joined]\n",
      "Index: []\n",
      "Cleaned DataFrame shape: (33654, 4)\n"
     ]
    }
   ],
   "source": [
    "# # df\n",
    "# Drop rows where 'text_joined' is empty\n",
    "df = df[df['text_joined'].str.len() > 0]\n",
    "\n",
    "print(df[df['text_joined'].str.len() == 0])  # Find any empty texts\n",
    "\n",
    "\n",
    "# Optionally, reset the index if needed\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the shape of the cleaned DataFrame to verify\n",
    "print(f'Cleaned DataFrame shape: {df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text, label, text_tokens, text_joined]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df[df['text_joined'].str.len() == 0])  # Find any empty texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "Training loss: 0.1932, Accuracy: 0.9428\n",
      "Validation Accuracy: 0.9822\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3332\n",
      "           1       0.97      0.99      0.98      3399\n",
      "\n",
      "    accuracy                           0.98      6731\n",
      "   macro avg       0.98      0.98      0.98      6731\n",
      "weighted avg       0.98      0.98      0.98      6731\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3237   95]\n",
      " [  25 3374]]\n",
      "Epoch 2/6\n",
      "Training loss: 0.0912, Accuracy: 0.9790\n",
      "Validation Accuracy: 0.9808\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3332\n",
      "           1       0.97      0.99      0.98      3399\n",
      "\n",
      "    accuracy                           0.98      6731\n",
      "   macro avg       0.98      0.98      0.98      6731\n",
      "weighted avg       0.98      0.98      0.98      6731\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3224  108]\n",
      " [  21 3378]]\n",
      "Epoch 3/6\n",
      "Training loss: 0.0328, Accuracy: 0.9927\n",
      "Validation Accuracy: 0.9872\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3332\n",
      "           1       0.99      0.99      0.99      3399\n",
      "\n",
      "    accuracy                           0.99      6731\n",
      "   macro avg       0.99      0.99      0.99      6731\n",
      "weighted avg       0.99      0.99      0.99      6731\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3282   50]\n",
      " [  36 3363]]\n",
      "Epoch 4/6\n",
      "Training loss: 0.0196, Accuracy: 0.9960\n",
      "Validation Accuracy: 0.9881\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3332\n",
      "           1       0.99      0.99      0.99      3399\n",
      "\n",
      "    accuracy                           0.99      6731\n",
      "   macro avg       0.99      0.99      0.99      6731\n",
      "weighted avg       0.99      0.99      0.99      6731\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3286   46]\n",
      " [  34 3365]]\n",
      "Epoch 5/6\n",
      "Training loss: 0.0123, Accuracy: 0.9975\n",
      "Validation Accuracy: 0.9887\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3332\n",
      "           1       0.99      0.99      0.99      3399\n",
      "\n",
      "    accuracy                           0.99      6731\n",
      "   macro avg       0.99      0.99      0.99      6731\n",
      "weighted avg       0.99      0.99      0.99      6731\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3289   43]\n",
      " [  33 3366]]\n",
      "Epoch 6/6\n",
      "Training loss: 0.0115, Accuracy: 0.9977\n",
      "Validation Accuracy: 0.9886\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3332\n",
      "           1       0.99      0.99      0.99      3399\n",
      "\n",
      "    accuracy                           0.99      6731\n",
      "   macro avg       0.99      0.99      0.99      6731\n",
      "weighted avg       0.99      0.99      0.99      6731\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3289   43]\n",
      " [  34 3365]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.empty_cache():\n",
    "    print(\"Memory Cleaned\")\n",
    "\n",
    "# Dataset preparation (assuming your data is already preprocessed)\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Load your dataset\n",
    "X = df['text_joined'].tolist()  # Preprocessed texts\n",
    "y = df['label'].tolist()        # Labels\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the tokenizer and define dataset parameters\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 21\n",
    "\n",
    "# Create PyTorch Dataset objects\n",
    "train_dataset = TextDataset(X_train, y_train, tokenizer, MAX_LEN)\n",
    "test_dataset = TextDataset(X_test, y_test, tokenizer, MAX_LEN)\n",
    "\n",
    "# DataLoader for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Initialize the ALBERT model for sequence classification (binary classification)\n",
    "model = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5,weight_decay=0.0001)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)  # Reduces LR by 90% every 2 epochs\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), total_loss / len(data_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    preds_all, labels_all = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            \n",
    "            preds_all.extend(preds.cpu().numpy())\n",
    "            labels_all.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = correct_predictions.double() / len(data_loader.dataset)\n",
    "    return accuracy, preds_all, labels_all\n",
    "\n",
    "# Training\n",
    "EPOCHS = 6\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}')\n",
    "    train_acc, train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    print(f'Training loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}')\n",
    "    \n",
    "    val_acc, y_pred, y_true = eval_model(model, test_loader, device)\n",
    "    print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "    print(f'Classification Report:\\n{classification_report(y_true, y_pred)}')\n",
    "    print(f'Confusion Matrix:\\n{confusion_matrix(y_true, y_pred)}')\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "del model  # Delete the BERT model (or any other large model)\n",
    "torch.cuda.empty_cache()  # Clear unused memory\n",
    "\n",
    "# Save the model\n",
    "# model.save_pretrained(\"albert_finetuned_model\")\n",
    "# tokenizer.save_pretrained(\"albert_finetuned_tokenizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mmodel\u001b[49m  \u001b[38;5;66;03m# Delete the BERT model (or any other large model)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()  \u001b[38;5;66;03m# Clear unused memory\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model  # Delete the BERT model (or any other large model)\n",
    "torch.cuda.empty_cache()  # Clear unused memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "12.4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "print(torch.version.cuda)  # Displays the version of CUDA used by PyTorch\n",
    "print(torch.cuda.is_available())  # Checks if CUDA is available\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Tue_Feb_27_16:28:36_Pacific_Standard_Time_2024\n",
      "Cuda compilation tools, release 12.4, V12.4.99\n",
      "Build cuda_12.4.r12.4/compiler.33961263_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# import torchtext\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "# print(\"TorchText version:\", torchtext.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2.BiLSTM </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text, label, text_tokens, text_joined]\n",
      "Index: []\n",
      "Cleaned DataFrame shape: (33654, 4)\n"
     ]
    }
   ],
   "source": [
    "# # df\n",
    "# Drop rows where 'text_joined' is empty\n",
    "df = df[df['text_joined'].str.len() > 0]\n",
    "\n",
    "print(df[df['text_joined'].str.len() == 0])  # Find any empty texts\n",
    "\n",
    "\n",
    "# Optionally, reset the index if needed\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the shape of the cleaned DataFrame to verify\n",
    "print(f'Cleaned DataFrame shape: {df.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [text, label, text_tokens, text_joined]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df[df['text_joined'].str.len() == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()  # Clear unused memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1 is starting.\n",
      "Epoch 1/10, Loss: 0.2752, Val Loss: 0.1258\n",
      "Epoch 2 is starting.\n",
      "Epoch 2/10, Loss: 0.1196, Val Loss: 0.0967\n",
      "Epoch 3 is starting.\n",
      "Epoch 3/10, Loss: 0.0898, Val Loss: 0.0748\n",
      "Epoch 4 is starting.\n",
      "Epoch 4/10, Loss: 0.0711, Val Loss: 0.0654\n",
      "Epoch 5 is starting.\n",
      "Epoch 5/10, Loss: 0.0572, Val Loss: 0.0614\n",
      "Epoch 6 is starting.\n",
      "Epoch 6/10, Loss: 0.0483, Val Loss: 0.0510\n",
      "Epoch 7 is starting.\n",
      "Epoch 7/10, Loss: 0.0406, Val Loss: 0.0473\n",
      "Epoch 8 is starting.\n",
      "Epoch 8/10, Loss: 0.0343, Val Loss: 0.0613\n",
      "Epoch 9 is starting.\n",
      "Epoch 9/10, Loss: 0.0287, Val Loss: 0.0410\n",
      "Epoch 10 is starting.\n",
      "Epoch 10/10, Loss: 0.0235, Val Loss: 0.0415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2522\n",
      "           1       0.98      0.99      0.99      2527\n",
      "\n",
      "    accuracy                           0.99      5049\n",
      "   macro avg       0.99      0.99      0.99      5049\n",
      "weighted avg       0.99      0.99      0.99      5049\n",
      "\n",
      "[[2478   44]\n",
      " [  18 2509]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Function to monitor GPU memory usage\n",
    "def print_gpu_memory_usage():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated_memory = torch.cuda.memory_allocated() / (1024 ** 3)  # GB\n",
    "        reserved_memory = torch.cuda.memory_reserved() / (1024 ** 3)    # GB\n",
    "        print(f\"Allocated GPU memory: {allocated_memory:.4f} GB\")\n",
    "        print(f\"Reserved GPU memory: {reserved_memory:.4f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available\")\n",
    "\n",
    "# Load GloVe embeddings from a local file\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# Specify the path to the downloaded GloVe embeddings file\n",
    "glove_file_path = 'E:/NLP/glove/glove.6B/glove.6B.300d.txt'  # Change this to your file path\n",
    "glove = load_glove_embeddings(glove_file_path)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df.loc[:,'label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# Prepare the data\n",
    "X = df['text_joined'].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # 70% training, 30% temporary\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 15% validation, 15% test\n",
    "\n",
    "# Tokenize and prepare embedding matrix\n",
    "def create_embedding_matrix(vocab):\n",
    "    embedding_matrix = np.zeros((len(vocab), 300))  # Assuming 100-dimensional GloVe vectors\n",
    "    for word, i in vocab.items():\n",
    "        if word in glove:\n",
    "            embedding_matrix[i] = glove[word]\n",
    "        else:\n",
    "            # Use random initialization for OOV tokens\n",
    "            embedding_matrix[i] = np.random.normal(size=(300,))\n",
    "    return embedding_matrix\n",
    "\n",
    "# Create vocabulary\n",
    "def create_vocab(texts):\n",
    "    vocab = {}\n",
    "    index = 0\n",
    "    for text in texts:\n",
    "        for word in word_tokenize(text.lower()):\n",
    "            if word not in vocab:\n",
    "                vocab[word] = index\n",
    "                index += 1\n",
    "    # Add OOV token\n",
    "    vocab['<OOV>'] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "# Create vocabulary and embedding matrix\n",
    "vocab = create_vocab(X_train)\n",
    "embedding_matrix = create_embedding_matrix(vocab)\n",
    "\n",
    "# Create datasets\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, vocab):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        # Convert text to indices, handle OOV words\n",
    "        indices = [self.vocab.get(word, self.vocab['<OOV>']) for word in word_tokenize(text.lower())]\n",
    "        return torch.tensor(indices, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Custom collate function to pad sequences and manage lengths\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    lengths = [len(text) for text in texts]\n",
    "    texts_padded = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels)\n",
    "    return texts_padded, labels, torch.tensor(lengths)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TextDataset(X_train, y_train, vocab)\n",
    "val_dataset = TextDataset(X_val, y_val, vocab)\n",
    "test_dataset = TextDataset(X_test, y_test, vocab)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=20, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=20, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=20, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Define BiLSTM Model with dropout and packed sequences\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, embedding_matrix):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=False)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=3, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Dropout layer to prevent overfitting\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # *2 for bidirectional\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed_embedded = pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_lstm_out, _ = self.lstm(packed_embedded)\n",
    "        lstm_out, _ = pad_packed_sequence(packed_lstm_out, batch_first=True)\n",
    "        \n",
    "        # Apply max pooling over time steps instead of using just the last hidden state\n",
    "        pooled_out = torch.max(lstm_out, dim=1)[0]\n",
    "        out = self.dropout(pooled_out)  # Apply dropout after LSTM\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = BiLSTM(vocab_size=len(vocab), embedding_dim=300, hidden_dim=128, output_dim=2, embedding_matrix=embedding_matrix).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.00005, weight_decay=5e-5)\n",
    "\n",
    "# Early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Training function with validation and early stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5):\n",
    "    early_stopping = EarlyStopping(patience=3)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode for the training loop\n",
    "        total_loss = 0\n",
    "        val_loss = 0\n",
    "        print(f\"Epoch {epoch+1} is starting.\")\n",
    "\n",
    "        # Training loop\n",
    "        for texts, labels, lengths in train_loader:\n",
    "            texts, labels, lengths = texts.to(device), labels.to(device), lengths.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(texts, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()  # Set the model to evaluation mode for the validation loop\n",
    "        with torch.no_grad():  # Disable gradient calculation for validation\n",
    "            for texts, labels, lengths in val_loader:\n",
    "                texts, labels, lengths = texts.to(device), labels.to(device), lengths.to(device)\n",
    "                outputs = model(texts, lengths)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}')\n",
    "\n",
    "        Early stopping check\n",
    "        early_stopping(val_loss/len(val_loader))\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "\n",
    "# Evaluation function with classification report and confusion matrix\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels, lengths in test_loader:\n",
    "            texts, labels, lengths = texts.to(device), labels.to(device), lengths.to(device)\n",
    "            outputs = model(texts, lengths)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Cross-validation (placeholder)\n",
    "# Here, you could use sklearn.model_selection.KFold or similar to split data and train the model on each split\n",
    "\n",
    "# Train the model with early stopping\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model  # Delete the BERT model (or any other large model)\n",
    "torch.cuda.empty_cache()  # Clear unused memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Dropout: A dropout layer with p=0.5 is added after the LSTM and fully connected layers to reduce overfitting.<br>\n",
    "\n",
    "2.Validation Set: The data is split into training, validation, and test sets, and validation performance is monitored.<br>\n",
    "\n",
    "3.Early Stopping: A class for early stopping is implemented, which monitors validation loss and stops training if there is no improvement for 3 consecutive epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
